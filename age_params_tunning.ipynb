{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"spMVAySTSEZ1","cell_type":"markdown","source":"# Colab setup","metadata":{"id":"spMVAySTSEZ1"}},{"id":"WyOYsMF2SEZ3","cell_type":"code","source":"import sys\n# if \"google.colab\" in str(get_ipython()):\n! {sys.executable} -m pip install pytorch-lifestream\n! {sys.executable} -m pip install catboost\n! {sys.executable} -m pip install torchmetrics","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"WyOYsMF2SEZ3","outputId":"d4de792a-68f1-4f17-ddb0-120d89f7b39f","trusted":true,"execution":{"iopub.status.busy":"2025-05-08T16:32:01.167837Z","iopub.execute_input":"2025-05-08T16:32:01.168122Z","iopub.status.idle":"2025-05-08T16:32:19.267157Z","shell.execute_reply.started":"2025-05-08T16:32:01.168099Z","shell.execute_reply":"2025-05-08T16:32:19.266355Z"}},"outputs":[{"name":"stdout","text":"Collecting pytorch-lifestream\n  Downloading pytorch-lifestream-0.6.0.tar.gz (163 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.4/163.4 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: duckdb in /usr/local/lib/python3.10/dist-packages (from pytorch-lifestream) (1.1.3)\nCollecting hydra-core>=1.1.2 (from pytorch-lifestream)\n  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\nRequirement already satisfied: numpy>=1.21.5 in /usr/local/lib/python3.10/dist-packages (from pytorch-lifestream) (1.26.4)\nRequirement already satisfied: omegaconf in /usr/local/lib/python3.10/dist-packages (from pytorch-lifestream) (2.3.0)\nRequirement already satisfied: pandas>=1.3.5 in /usr/local/lib/python3.10/dist-packages (from pytorch-lifestream) (2.2.3)\nRequirement already satisfied: pyarrow>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from pytorch-lifestream) (19.0.1)\nRequirement already satisfied: pytorch-lightning>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lifestream) (2.5.0.post0)\nRequirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from pytorch-lifestream) (1.2.2)\nRequirement already satisfied: torch>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lifestream) (2.5.1+cu121)\nRequirement already satisfied: torchmetrics>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lifestream) (1.6.1)\nRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from pytorch-lifestream) (4.47.0)\nRequirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from hydra-core>=1.1.2->pytorch-lifestream) (4.9.3)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from hydra-core>=1.1.2->pytorch-lifestream) (24.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.5->pytorch-lifestream) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.5->pytorch-lifestream) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.5->pytorch-lifestream) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.5->pytorch-lifestream) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.5->pytorch-lifestream) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.5->pytorch-lifestream) (2.4.1)\nRequirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from omegaconf->pytorch-lifestream) (6.0.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.5->pytorch-lifestream) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.5->pytorch-lifestream) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.5->pytorch-lifestream) (2025.1)\nRequirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning>=1.6.0->pytorch-lifestream) (4.67.1)\nRequirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning>=1.6.0->pytorch-lifestream) (2024.12.0)\nRequirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning>=1.6.0->pytorch-lifestream) (4.12.2)\nRequirement already satisfied: lightning-utilities>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning>=1.6.0->pytorch-lifestream) (0.12.0)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.2->pytorch-lifestream) (1.13.1)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.2->pytorch-lifestream) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.2->pytorch-lifestream) (3.5.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->pytorch-lifestream) (3.17.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->pytorch-lifestream) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->pytorch-lifestream) (3.1.4)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->pytorch-lifestream) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.12.0->pytorch-lifestream) (1.3.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers->pytorch-lifestream) (0.29.0)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->pytorch-lifestream) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers->pytorch-lifestream) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers->pytorch-lifestream) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers->pytorch-lifestream) (0.4.5)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning>=1.6.0->pytorch-lifestream) (3.11.12)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.10.0->pytorch-lightning>=1.6.0->pytorch-lifestream) (75.1.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.3.5->pytorch-lifestream) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.12.0->pytorch-lifestream) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.21.5->pytorch-lifestream) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.21.5->pytorch-lifestream) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.21.5->pytorch-lifestream) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.21.5->pytorch-lifestream) (2024.2.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->pytorch-lifestream) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->pytorch-lifestream) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->pytorch-lifestream) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->pytorch-lifestream) (2025.1.31)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.6.0->pytorch-lifestream) (2.4.6)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.6.0->pytorch-lifestream) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.6.0->pytorch-lifestream) (5.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.6.0->pytorch-lifestream) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.6.0->pytorch-lifestream) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.6.0->pytorch-lifestream) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.6.0->pytorch-lifestream) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.6.0->pytorch-lifestream) (1.18.3)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.21.5->pytorch-lifestream) (2024.2.0)\nDownloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: pytorch-lifestream\n  Building wheel for pytorch-lifestream (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for pytorch-lifestream: filename=pytorch_lifestream-0.6.0-py3-none-any.whl size=274670 sha256=7e74f20c1fc25a8351042fd81747cc33dd17dcf6322fa2abf4d2e0b9695698f2\n  Stored in directory: /root/.cache/pip/wheels/90/76/b4/0a944bc7c5a69201e4d757cc54886971117a2a581740e7f11d\nSuccessfully built pytorch-lifestream\nInstalling collected packages: hydra-core, pytorch-lifestream\nSuccessfully installed hydra-core-1.3.2 pytorch-lifestream-0.6.0\nRequirement already satisfied: catboost in /usr/local/lib/python3.10/dist-packages (1.2.7)\nRequirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.3)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.5)\nRequirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.26.4)\nRequirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (2.2.3)\nRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.13.1)\nRequirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.24.1)\nRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.17.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<2.0,>=1.16.0->catboost) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<2.0,>=1.16.0->catboost) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<2.0,>=1.16.0->catboost) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<2.0,>=1.16.0->catboost) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<2.0,>=1.16.0->catboost) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<2.0,>=1.16.0->catboost) (2.4.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2025.1)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.55.3)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.7)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (24.2)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (11.0.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.2.0)\nRequirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (9.0.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2.0,>=1.16.0->catboost) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2.0,>=1.16.0->catboost) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<2.0,>=1.16.0->catboost) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<2.0,>=1.16.0->catboost) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<2.0,>=1.16.0->catboost) (2024.2.0)\nRequirement already satisfied: torchmetrics in /usr/local/lib/python3.10/dist-packages (1.6.1)\nRequirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.26.4)\nRequirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (24.2)\nRequirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.5.1+cu121)\nRequirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (0.12.0)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.1.0)\nRequirement already satisfied: typing_extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>1.20.0->torchmetrics) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>1.20.0->torchmetrics) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>1.20.0->torchmetrics) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>1.20.0->torchmetrics) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>1.20.0->torchmetrics) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>1.20.0->torchmetrics) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (3.17.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.0.0->torchmetrics) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>1.20.0->torchmetrics) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>1.20.0->torchmetrics) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>1.20.0->torchmetrics) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>1.20.0->torchmetrics) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>1.20.0->torchmetrics) (2024.2.0)\n","output_type":"stream"}],"execution_count":1},{"id":"T6ZAv6VUd1pq","cell_type":"markdown","source":"# Supervised task","metadata":{"id":"T6ZAv6VUd1pq"}},{"id":"ipR01Z_jd1pt","cell_type":"markdown","source":"## Prepare your data\n\n- Use `Pyspark` in local or cluster mode for big dataset and `Pandas` for small.\n- Split data into required parts (train, valid, test, ...).\n- Use `ptls.preprocessing` for simple data preparation.\n- Transform features to compatible format using `Pyspark` or `Pandas` functions.\nYou can also use `ptls.data_load.preprocessing` for common data transformation patterns.\n- Split sequences to `ptls-data` format with `ptls.data_load.split_tools`. Save prepared data into `Parquet` format or\nkeep it in memory (`Pickle` also works).\n- Use one of the available `ptls.data_load.datasets` to define input for the models.","metadata":{"id":"ipR01Z_jd1pt"}},{"id":"Om-SP9LKd1pv","cell_type":"code","source":"import torch\n\nimport numpy as np\nimport pandas as pd\nimport torchmetrics\nimport pytorch_lightning as pl\n\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom functools import partial\nfrom ptls.frames import PtlsDataModule\nfrom ptls.nn import TrxEncoder, RnnSeqEncoder, Head\nfrom ptls.data_load.datasets import MemoryMapDataset\nfrom ptls.preprocessing import PandasDataPreprocessor\nfrom ptls.frames.supervised import SeqToTargetDataset, SequenceToTarget\nfrom ptls.data_load.utils import collate_feature_dict\nfrom ptls.frames.inference_module import InferenceModule\nfrom ptls.frames.coles import CoLESModule\nfrom ptls.frames.coles.multimodal_dataset import MultiModalIterableDataset\nfrom pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n","metadata":{"colab":{"background_save":true},"id":"Om-SP9LKd1pv","trusted":true,"execution":{"iopub.status.busy":"2025-05-08T16:32:19.268513Z","iopub.execute_input":"2025-05-08T16:32:19.268756Z","iopub.status.idle":"2025-05-08T16:32:44.337509Z","shell.execute_reply.started":"2025-05-08T16:32:19.268736Z","shell.execute_reply":"2025-05-08T16:32:44.336747Z"}},"outputs":[],"execution_count":2},{"id":"3cb16883-4df4-4c59-982c-2533cabb7f65","cell_type":"code","source":"from functools import partial\nfrom datetime import timedelta\n\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport catboost\n\nimport torch\nimport pytorch_lightning as pl\nfrom torch.utils.data.dataloader import DataLoader\nfrom pytorch_lightning.loggers import TensorBoardLogger\n\nfrom sklearn.model_selection import train_test_split\n\nfrom ptls.nn import TrxEncoder\nfrom ptls.nn.seq_encoder.rnn_encoder import RnnEncoder\nfrom ptls.frames import PtlsDataModule\nfrom ptls.frames.coles import CoLESModule\nfrom ptls.frames.coles.split_strategy import SampleSlices\nfrom ptls.frames.coles.multimodal_dataset import MultiModalDataset\nfrom ptls.frames.coles.multimodal_dataset import MultiModalIterableDataset\nfrom ptls.frames.coles.multimodal_dataset import MultiModalSortTimeSeqEncoderContainer\nfrom ptls.frames.coles.multimodal_inference_dataset import MultiModalInferenceDataset\nfrom ptls.frames.coles.multimodal_inference_dataset import MultiModalInferenceIterableDataset\nfrom ptls.frames.inference_module import InferenceModuleMultimodal\nfrom ptls.data_load.iterable_processing import SeqLenFilter\nfrom ptls.data_load import IterableProcessingDataset\nfrom ptls.data_load.utils import collate_feature_dict\nfrom ptls.data_load.datasets import MemoryMapDataset\nfrom ptls.preprocessing import PandasDataPreprocessor","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T16:32:44.338724Z","iopub.execute_input":"2025-05-08T16:32:44.339380Z","iopub.status.idle":"2025-05-08T16:32:45.056919Z","shell.execute_reply.started":"2025-05-08T16:32:44.339355Z","shell.execute_reply":"2025-05-08T16:32:45.056298Z"}},"outputs":[],"execution_count":3},{"id":"H5e7oTeqd1py","cell_type":"code","source":"df_target = pd.read_csv(\n    \"https://huggingface.co/datasets/dllllb/age-group-prediction/resolve/main/train_target.csv?download=true\"\n)\ndf_target","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":206},"id":"H5e7oTeqd1py","outputId":"3ad59ce8-fe24-4f3b-dc98-a35947910692","trusted":true,"execution":{"iopub.status.busy":"2025-05-08T16:32:45.058000Z","iopub.execute_input":"2025-05-08T16:32:45.058540Z","iopub.status.idle":"2025-05-08T16:32:45.287022Z","shell.execute_reply.started":"2025-05-08T16:32:45.058516Z","shell.execute_reply":"2025-05-08T16:32:45.286322Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"       client_id  bins\n0          24662     2\n1           1046     0\n2          34089     2\n3          34848     1\n4          47076     3\n...          ...   ...\n29995      14303     1\n29996      22301     2\n29997      25731     0\n29998      16820     3\n29999       5265     0\n\n[30000 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>client_id</th>\n      <th>bins</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>24662</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1046</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>34089</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>34848</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>47076</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>29995</th>\n      <td>14303</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>29996</th>\n      <td>22301</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>29997</th>\n      <td>25731</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>29998</th>\n      <td>16820</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>29999</th>\n      <td>5265</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>30000 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":4},{"id":"pvunZAm9d1pz","cell_type":"code","source":"# df_target_train, df_target_test = train_test_split(\n#     df_target, test_size=7000, stratify=df_target[\"bins\"], random_state=142)\n# df_target_train, df_target_valid = train_test_split(\n#     df_target_train, test_size=3000, stratify=df_target_train[\"bins\"], random_state=142)\n# print(\"Split {} records to train: {}, valid: {}, test: {}\".format(\n#     *[\n#       len(df)\n#       for df in [df_target, df_target_train, df_target_valid, df_target_test]\n#     ]\n# ))","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"pvunZAm9d1pz","outputId":"d8c825c8-9a2a-434a-8a1e-284d84373479","trusted":true,"execution":{"iopub.status.busy":"2025-05-08T16:32:45.287777Z","iopub.execute_input":"2025-05-08T16:32:45.287989Z","iopub.status.idle":"2025-05-08T16:32:45.291527Z","shell.execute_reply.started":"2025-05-08T16:32:45.287971Z","shell.execute_reply":"2025-05-08T16:32:45.290517Z"}},"outputs":[],"execution_count":5},{"id":"Of3-MPEBd1pz","cell_type":"code","source":"df_trx = pd.read_csv(\n    \"https://huggingface.co/datasets/dllllb/age-group-prediction/resolve/main/transactions_train.csv.gz?download=true\",\n    compression=\"gzip\"\n)\ndf_trx","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":423},"id":"Of3-MPEBd1pz","outputId":"24771ae2-1236-40a0-da8c-5bdb9401ff56","trusted":true,"execution":{"iopub.status.busy":"2025-05-08T16:32:45.292402Z","iopub.execute_input":"2025-05-08T16:32:45.292730Z","iopub.status.idle":"2025-05-08T16:32:56.170151Z","shell.execute_reply.started":"2025-05-08T16:32:45.292707Z","shell.execute_reply":"2025-05-08T16:32:56.169309Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"          client_id  trans_date  small_group  amount_rur\n0             33172           6            4      71.463\n1             33172           6           35      45.017\n2             33172           8           11      13.887\n3             33172           9           11      15.983\n4             33172          10           11      21.341\n...             ...         ...          ...         ...\n26450572      43300         727           25       7.602\n26450573      43300         727           15       3.709\n26450574      43300         727            1       6.448\n26450575      43300         727           11      24.669\n26450576      43300         729            3      19.408\n\n[26450577 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>client_id</th>\n      <th>trans_date</th>\n      <th>small_group</th>\n      <th>amount_rur</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>33172</td>\n      <td>6</td>\n      <td>4</td>\n      <td>71.463</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>33172</td>\n      <td>6</td>\n      <td>35</td>\n      <td>45.017</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>33172</td>\n      <td>8</td>\n      <td>11</td>\n      <td>13.887</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>33172</td>\n      <td>9</td>\n      <td>11</td>\n      <td>15.983</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>33172</td>\n      <td>10</td>\n      <td>11</td>\n      <td>21.341</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>26450572</th>\n      <td>43300</td>\n      <td>727</td>\n      <td>25</td>\n      <td>7.602</td>\n    </tr>\n    <tr>\n      <th>26450573</th>\n      <td>43300</td>\n      <td>727</td>\n      <td>15</td>\n      <td>3.709</td>\n    </tr>\n    <tr>\n      <th>26450574</th>\n      <td>43300</td>\n      <td>727</td>\n      <td>1</td>\n      <td>6.448</td>\n    </tr>\n    <tr>\n      <th>26450575</th>\n      <td>43300</td>\n      <td>727</td>\n      <td>11</td>\n      <td>24.669</td>\n    </tr>\n    <tr>\n      <th>26450576</th>\n      <td>43300</td>\n      <td>729</td>\n      <td>3</td>\n      <td>19.408</td>\n    </tr>\n  </tbody>\n</table>\n<p>26450577 rows × 4 columns</p>\n</div>"},"metadata":{}}],"execution_count":6},{"id":"428feb87-4e8c-4ac9-8c54-78640d554f16","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"e3d8789e-25cc-44bc-8ab6-5a0e431a6a90","cell_type":"code","source":"len(df_target)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T16:32:56.171005Z","iopub.execute_input":"2025-05-08T16:32:56.171360Z","iopub.status.idle":"2025-05-08T16:32:56.176814Z","shell.execute_reply.started":"2025-05-08T16:32:56.171337Z","shell.execute_reply":"2025-05-08T16:32:56.176072Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"30000"},"metadata":{}}],"execution_count":7},{"id":"fff740f8-ed6b-4905-9352-f35905bbe4b0","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"1ec6d9d7-4fc4-4b20-8820-d23cb2cafb1e","cell_type":"code","source":"len(df_trx)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T16:32:56.179086Z","iopub.execute_input":"2025-05-08T16:32:56.179309Z","iopub.status.idle":"2025-05-08T16:32:56.190111Z","shell.execute_reply.started":"2025-05-08T16:32:56.179291Z","shell.execute_reply":"2025-05-08T16:32:56.189481Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"26450577"},"metadata":{}}],"execution_count":8},{"id":"0a5e9fa4-0d35-48eb-8f68-f906731ae1e7","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"d885c788-eada-4416-b878-d8d1e25d9591","cell_type":"code","source":"sourceA = df_trx[[\"client_id\", \"trans_date\", \"small_group\"]]\nsourceB = df_trx[[\"client_id\", \"trans_date\", \"amount_rur\"]]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T16:32:56.191739Z","iopub.execute_input":"2025-05-08T16:32:56.191932Z","iopub.status.idle":"2025-05-08T16:32:56.663079Z","shell.execute_reply.started":"2025-05-08T16:32:56.191914Z","shell.execute_reply":"2025-05-08T16:32:56.662438Z"}},"outputs":[],"execution_count":9},{"id":"6f14522c-f37d-4747-91bd-f86d9d02cb80","cell_type":"code","source":"sourceA_drop_indices = np.random.choice(sourceA.index, int(150000), replace=False)\nsourceB_drop_indices = np.random.choice(sourceB.index, int(450000), replace=False)\n\nsourceA = sourceA.drop(sourceA_drop_indices).reset_index(drop=True)\nsourceB = sourceB.drop(sourceB_drop_indices).reset_index(drop=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T16:32:56.663816Z","iopub.execute_input":"2025-05-08T16:32:56.664039Z","iopub.status.idle":"2025-05-08T16:33:01.848421Z","shell.execute_reply.started":"2025-05-08T16:32:56.664020Z","shell.execute_reply":"2025-05-08T16:33:01.847668Z"}},"outputs":[],"execution_count":10},{"id":"7bb6cd53-c7f2-4650-a11c-116f90cd3f0f","cell_type":"code","source":"sourceA[\"trans_date\"] = sourceA[\"trans_date\"].apply(lambda x: x * 3600)\nsourceB[\"trans_date\"] = sourceB[\"trans_date\"].apply(lambda x: x * 3600)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T16:33:01.849086Z","iopub.execute_input":"2025-05-08T16:33:01.849334Z","iopub.status.idle":"2025-05-08T16:33:22.346088Z","shell.execute_reply.started":"2025-05-08T16:33:01.849314Z","shell.execute_reply":"2025-05-08T16:33:22.345400Z"}},"outputs":[],"execution_count":11},{"id":"372c69e4-ad51-436c-a66c-092917254c1e","cell_type":"code","source":"sourceA_preprocessor = PandasDataPreprocessor(\n    col_id=\"client_id\",\n    col_event_time=\"trans_date\",\n    event_time_transformation=\"none\",\n    cols_category=[\"small_group\"],\n    return_records=False,\n)\n\nsourceB_preprocessor = PandasDataPreprocessor(\n    col_id=\"client_id\",\n    col_event_time=\"trans_date\",\n    event_time_transformation=\"none\",\n    cols_numerical=[\"amount_rur\"],\n    return_records=False,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T16:33:22.346859Z","iopub.execute_input":"2025-05-08T16:33:22.347086Z","iopub.status.idle":"2025-05-08T16:33:22.351577Z","shell.execute_reply.started":"2025-05-08T16:33:22.347067Z","shell.execute_reply":"2025-05-08T16:33:22.350513Z"}},"outputs":[],"execution_count":12},{"id":"88d0eef5-a35c-4be1-bc8b-820cf55e758c","cell_type":"code","source":"processed_sourceA = sourceA_preprocessor.fit_transform(sourceA)\nprocessed_sourceB = sourceB_preprocessor.fit_transform(sourceB)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T16:33:22.352359Z","iopub.execute_input":"2025-05-08T16:33:22.352614Z","iopub.status.idle":"2025-05-08T16:34:26.087959Z","shell.execute_reply.started":"2025-05-08T16:33:22.352595Z","shell.execute_reply":"2025-05-08T16:34:26.087175Z"}},"outputs":[],"execution_count":13},{"id":"710408d0-befe-4fb0-8967-448f2291bf6e","cell_type":"code","source":"processed_sourceA.columns = [\n    \"sourceA_\" + str(col) if str(col) != \"client_id\" else str(col)\n    for col in processed_sourceA.columns\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T16:34:26.094164Z","iopub.execute_input":"2025-05-08T16:34:26.095014Z","iopub.status.idle":"2025-05-08T16:34:26.099453Z","shell.execute_reply.started":"2025-05-08T16:34:26.094990Z","shell.execute_reply":"2025-05-08T16:34:26.098780Z"}},"outputs":[],"execution_count":14},{"id":"b1f3e6dd-25f8-4fb9-a93a-829332b8fba7","cell_type":"code","source":"processed_sourceB.columns = [\n    \"sourceB_\" + str(col) if str(col) != \"client_id\" else str(col)\n    for col in processed_sourceB.columns\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T16:34:26.100240Z","iopub.execute_input":"2025-05-08T16:34:26.100534Z","iopub.status.idle":"2025-05-08T16:34:26.115831Z","shell.execute_reply.started":"2025-05-08T16:34:26.100507Z","shell.execute_reply":"2025-05-08T16:34:26.115072Z"}},"outputs":[],"execution_count":15},{"id":"4182f6b0-9f59-463d-aaec-3aa17ce79dba","cell_type":"code","source":"joined_data = processed_sourceA.merge(processed_sourceB, how=\"outer\", on=\"client_id\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T16:34:26.116779Z","iopub.execute_input":"2025-05-08T16:34:26.117123Z","iopub.status.idle":"2025-05-08T16:34:26.135331Z","shell.execute_reply.started":"2025-05-08T16:34:26.117095Z","shell.execute_reply":"2025-05-08T16:34:26.134611Z"}},"outputs":[],"execution_count":16},{"id":"7856789e-a955-4caa-a8ea-56e9f6743d73","cell_type":"code","source":"joined_data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T16:34:26.136167Z","iopub.execute_input":"2025-05-08T16:34:26.136479Z","iopub.status.idle":"2025-05-08T16:34:27.441607Z","shell.execute_reply.started":"2025-05-08T16:34:26.136450Z","shell.execute_reply":"2025-05-08T16:34:27.440697Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"       client_id                                 sourceA_trans_date  \\\n0              4  [tensor(0), tensor(7200), tensor(10800), tenso...   \n1              6  [tensor(0), tensor(18000), tensor(36000), tens...   \n2              7  [tensor(3600), tensor(7200), tensor(43200), te...   \n3             10  [tensor(14400), tensor(14400), tensor(14400), ...   \n4             11  [tensor(0), tensor(7200), tensor(21600), tenso...   \n...          ...                                                ...   \n29995      49993  [tensor(3600), tensor(14400), tensor(14400), t...   \n29996      49995  [tensor(0), tensor(3600), tensor(3600), tensor...   \n29997      49996  [tensor(3600), tensor(3600), tensor(7200), ten...   \n29998      49997  [tensor(3600), tensor(7200), tensor(10800), te...   \n29999      49998  [tensor(57600), tensor(57600), tensor(57600), ...   \n\n                                      sourceA_event_time  \\\n0      [tensor(0), tensor(7200), tensor(10800), tenso...   \n1      [tensor(0), tensor(18000), tensor(36000), tens...   \n2      [tensor(3600), tensor(7200), tensor(43200), te...   \n3      [tensor(14400), tensor(14400), tensor(14400), ...   \n4      [tensor(0), tensor(7200), tensor(21600), tenso...   \n...                                                  ...   \n29995  [tensor(3600), tensor(14400), tensor(14400), t...   \n29996  [tensor(0), tensor(3600), tensor(3600), tensor...   \n29997  [tensor(3600), tensor(3600), tensor(7200), ten...   \n29998  [tensor(3600), tensor(7200), tensor(10800), te...   \n29999  [tensor(57600), tensor(57600), tensor(57600), ...   \n\n                                     sourceA_small_group  \\\n0      [tensor(1), tensor(3), tensor(1), tensor(1), t...   \n1      [tensor(4), tensor(3), tensor(1), tensor(3), t...   \n2      [tensor(3), tensor(53), tensor(1), tensor(5), ...   \n3      [tensor(16), tensor(1), tensor(53), tensor(10)...   \n4      [tensor(3), tensor(9), tensor(1), tensor(1), t...   \n...                                                  ...   \n29995  [tensor(10), tensor(49), tensor(36), tensor(21...   \n29996  [tensor(3), tensor(9), tensor(2), tensor(9), t...   \n29997  [tensor(13), tensor(1), tensor(5), tensor(47),...   \n29998  [tensor(1), tensor(1), tensor(1), tensor(1), t...   \n29999  [tensor(12), tensor(4), tensor(7), tensor(1), ...   \n\n                                      sourceB_trans_date  \\\n0      [tensor(0), tensor(7200), tensor(10800), tenso...   \n1      [tensor(0), tensor(18000), tensor(36000), tens...   \n2      [tensor(3600), tensor(7200), tensor(43200), te...   \n3      [tensor(14400), tensor(14400), tensor(14400), ...   \n4      [tensor(0), tensor(7200), tensor(21600), tenso...   \n...                                                  ...   \n29995  [tensor(3600), tensor(14400), tensor(14400), t...   \n29996  [tensor(0), tensor(3600), tensor(3600), tensor...   \n29997  [tensor(3600), tensor(3600), tensor(7200), ten...   \n29998  [tensor(3600), tensor(7200), tensor(10800), te...   \n29999  [tensor(57600), tensor(57600), tensor(57600), ...   \n\n                                      sourceB_event_time  \\\n0      [tensor(0), tensor(7200), tensor(10800), tenso...   \n1      [tensor(0), tensor(18000), tensor(36000), tens...   \n2      [tensor(3600), tensor(7200), tensor(43200), te...   \n3      [tensor(14400), tensor(14400), tensor(14400), ...   \n4      [tensor(0), tensor(7200), tensor(21600), tenso...   \n...                                                  ...   \n29995  [tensor(3600), tensor(14400), tensor(14400), t...   \n29996  [tensor(0), tensor(3600), tensor(3600), tensor...   \n29997  [tensor(3600), tensor(3600), tensor(7200), ten...   \n29998  [tensor(3600), tensor(7200), tensor(10800), te...   \n29999  [tensor(57600), tensor(57600), tensor(57600), ...   \n\n                                      sourceB_amount_rur  \n0      [tensor(10.2090, dtype=torch.float64), tensor(...  \n1      [tensor(4.0540, dtype=torch.float64), tensor(1...  \n2      [tensor(18.3190, dtype=torch.float64), tensor(...  \n3      [tensor(17.4020, dtype=torch.float64), tensor(...  \n4      [tensor(17.2510, dtype=torch.float64), tensor(...  \n...                                                  ...  \n29995  [tensor(78.8800, dtype=torch.float64), tensor(...  \n29996  [tensor(25.8770, dtype=torch.float64), tensor(...  \n29997  [tensor(215.6500, dtype=torch.float64), tensor...  \n29998  [tensor(32.1940, dtype=torch.float64), tensor(...  \n29999  [tensor(9.1130, dtype=torch.float64), tensor(3...  \n\n[30000 rows x 7 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>client_id</th>\n      <th>sourceA_trans_date</th>\n      <th>sourceA_event_time</th>\n      <th>sourceA_small_group</th>\n      <th>sourceB_trans_date</th>\n      <th>sourceB_event_time</th>\n      <th>sourceB_amount_rur</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4</td>\n      <td>[tensor(0), tensor(7200), tensor(10800), tenso...</td>\n      <td>[tensor(0), tensor(7200), tensor(10800), tenso...</td>\n      <td>[tensor(1), tensor(3), tensor(1), tensor(1), t...</td>\n      <td>[tensor(0), tensor(7200), tensor(10800), tenso...</td>\n      <td>[tensor(0), tensor(7200), tensor(10800), tenso...</td>\n      <td>[tensor(10.2090, dtype=torch.float64), tensor(...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>6</td>\n      <td>[tensor(0), tensor(18000), tensor(36000), tens...</td>\n      <td>[tensor(0), tensor(18000), tensor(36000), tens...</td>\n      <td>[tensor(4), tensor(3), tensor(1), tensor(3), t...</td>\n      <td>[tensor(0), tensor(18000), tensor(36000), tens...</td>\n      <td>[tensor(0), tensor(18000), tensor(36000), tens...</td>\n      <td>[tensor(4.0540, dtype=torch.float64), tensor(1...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7</td>\n      <td>[tensor(3600), tensor(7200), tensor(43200), te...</td>\n      <td>[tensor(3600), tensor(7200), tensor(43200), te...</td>\n      <td>[tensor(3), tensor(53), tensor(1), tensor(5), ...</td>\n      <td>[tensor(3600), tensor(7200), tensor(43200), te...</td>\n      <td>[tensor(3600), tensor(7200), tensor(43200), te...</td>\n      <td>[tensor(18.3190, dtype=torch.float64), tensor(...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10</td>\n      <td>[tensor(14400), tensor(14400), tensor(14400), ...</td>\n      <td>[tensor(14400), tensor(14400), tensor(14400), ...</td>\n      <td>[tensor(16), tensor(1), tensor(53), tensor(10)...</td>\n      <td>[tensor(14400), tensor(14400), tensor(14400), ...</td>\n      <td>[tensor(14400), tensor(14400), tensor(14400), ...</td>\n      <td>[tensor(17.4020, dtype=torch.float64), tensor(...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11</td>\n      <td>[tensor(0), tensor(7200), tensor(21600), tenso...</td>\n      <td>[tensor(0), tensor(7200), tensor(21600), tenso...</td>\n      <td>[tensor(3), tensor(9), tensor(1), tensor(1), t...</td>\n      <td>[tensor(0), tensor(7200), tensor(21600), tenso...</td>\n      <td>[tensor(0), tensor(7200), tensor(21600), tenso...</td>\n      <td>[tensor(17.2510, dtype=torch.float64), tensor(...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>29995</th>\n      <td>49993</td>\n      <td>[tensor(3600), tensor(14400), tensor(14400), t...</td>\n      <td>[tensor(3600), tensor(14400), tensor(14400), t...</td>\n      <td>[tensor(10), tensor(49), tensor(36), tensor(21...</td>\n      <td>[tensor(3600), tensor(14400), tensor(14400), t...</td>\n      <td>[tensor(3600), tensor(14400), tensor(14400), t...</td>\n      <td>[tensor(78.8800, dtype=torch.float64), tensor(...</td>\n    </tr>\n    <tr>\n      <th>29996</th>\n      <td>49995</td>\n      <td>[tensor(0), tensor(3600), tensor(3600), tensor...</td>\n      <td>[tensor(0), tensor(3600), tensor(3600), tensor...</td>\n      <td>[tensor(3), tensor(9), tensor(2), tensor(9), t...</td>\n      <td>[tensor(0), tensor(3600), tensor(3600), tensor...</td>\n      <td>[tensor(0), tensor(3600), tensor(3600), tensor...</td>\n      <td>[tensor(25.8770, dtype=torch.float64), tensor(...</td>\n    </tr>\n    <tr>\n      <th>29997</th>\n      <td>49996</td>\n      <td>[tensor(3600), tensor(3600), tensor(7200), ten...</td>\n      <td>[tensor(3600), tensor(3600), tensor(7200), ten...</td>\n      <td>[tensor(13), tensor(1), tensor(5), tensor(47),...</td>\n      <td>[tensor(3600), tensor(3600), tensor(7200), ten...</td>\n      <td>[tensor(3600), tensor(3600), tensor(7200), ten...</td>\n      <td>[tensor(215.6500, dtype=torch.float64), tensor...</td>\n    </tr>\n    <tr>\n      <th>29998</th>\n      <td>49997</td>\n      <td>[tensor(3600), tensor(7200), tensor(10800), te...</td>\n      <td>[tensor(3600), tensor(7200), tensor(10800), te...</td>\n      <td>[tensor(1), tensor(1), tensor(1), tensor(1), t...</td>\n      <td>[tensor(3600), tensor(7200), tensor(10800), te...</td>\n      <td>[tensor(3600), tensor(7200), tensor(10800), te...</td>\n      <td>[tensor(32.1940, dtype=torch.float64), tensor(...</td>\n    </tr>\n    <tr>\n      <th>29999</th>\n      <td>49998</td>\n      <td>[tensor(57600), tensor(57600), tensor(57600), ...</td>\n      <td>[tensor(57600), tensor(57600), tensor(57600), ...</td>\n      <td>[tensor(12), tensor(4), tensor(7), tensor(1), ...</td>\n      <td>[tensor(57600), tensor(57600), tensor(57600), ...</td>\n      <td>[tensor(57600), tensor(57600), tensor(57600), ...</td>\n      <td>[tensor(9.1130, dtype=torch.float64), tensor(3...</td>\n    </tr>\n  </tbody>\n</table>\n<p>30000 rows × 7 columns</p>\n</div>"},"metadata":{}}],"execution_count":17},{"id":"6c977d07-5d04-4274-ae61-f6c596b55164","cell_type":"code","source":"joined_data = joined_data.applymap(lambda x: torch.tensor([]) if pd.isna(x) else x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T16:34:27.442444Z","iopub.execute_input":"2025-05-08T16:34:27.442738Z","iopub.status.idle":"2025-05-08T16:34:27.573214Z","shell.execute_reply.started":"2025-05-08T16:34:27.442715Z","shell.execute_reply":"2025-05-08T16:34:27.572328Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-18-c25978d77e3b>:1: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n  joined_data = joined_data.applymap(lambda x: torch.tensor([]) if pd.isna(x) else x)\n","output_type":"stream"}],"execution_count":18},{"id":"b2bd617d-ea90-4b5a-96cd-23ae101a21f5","cell_type":"code","source":"joined_data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T16:34:27.574352Z","iopub.execute_input":"2025-05-08T16:34:27.574698Z","iopub.status.idle":"2025-05-08T16:34:28.794339Z","shell.execute_reply.started":"2025-05-08T16:34:27.574664Z","shell.execute_reply":"2025-05-08T16:34:28.793500Z"}},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"       client_id                                 sourceA_trans_date  \\\n0              4  [tensor(0), tensor(7200), tensor(10800), tenso...   \n1              6  [tensor(0), tensor(18000), tensor(36000), tens...   \n2              7  [tensor(3600), tensor(7200), tensor(43200), te...   \n3             10  [tensor(14400), tensor(14400), tensor(14400), ...   \n4             11  [tensor(0), tensor(7200), tensor(21600), tenso...   \n...          ...                                                ...   \n29995      49993  [tensor(3600), tensor(14400), tensor(14400), t...   \n29996      49995  [tensor(0), tensor(3600), tensor(3600), tensor...   \n29997      49996  [tensor(3600), tensor(3600), tensor(7200), ten...   \n29998      49997  [tensor(3600), tensor(7200), tensor(10800), te...   \n29999      49998  [tensor(57600), tensor(57600), tensor(57600), ...   \n\n                                      sourceA_event_time  \\\n0      [tensor(0), tensor(7200), tensor(10800), tenso...   \n1      [tensor(0), tensor(18000), tensor(36000), tens...   \n2      [tensor(3600), tensor(7200), tensor(43200), te...   \n3      [tensor(14400), tensor(14400), tensor(14400), ...   \n4      [tensor(0), tensor(7200), tensor(21600), tenso...   \n...                                                  ...   \n29995  [tensor(3600), tensor(14400), tensor(14400), t...   \n29996  [tensor(0), tensor(3600), tensor(3600), tensor...   \n29997  [tensor(3600), tensor(3600), tensor(7200), ten...   \n29998  [tensor(3600), tensor(7200), tensor(10800), te...   \n29999  [tensor(57600), tensor(57600), tensor(57600), ...   \n\n                                     sourceA_small_group  \\\n0      [tensor(1), tensor(3), tensor(1), tensor(1), t...   \n1      [tensor(4), tensor(3), tensor(1), tensor(3), t...   \n2      [tensor(3), tensor(53), tensor(1), tensor(5), ...   \n3      [tensor(16), tensor(1), tensor(53), tensor(10)...   \n4      [tensor(3), tensor(9), tensor(1), tensor(1), t...   \n...                                                  ...   \n29995  [tensor(10), tensor(49), tensor(36), tensor(21...   \n29996  [tensor(3), tensor(9), tensor(2), tensor(9), t...   \n29997  [tensor(13), tensor(1), tensor(5), tensor(47),...   \n29998  [tensor(1), tensor(1), tensor(1), tensor(1), t...   \n29999  [tensor(12), tensor(4), tensor(7), tensor(1), ...   \n\n                                      sourceB_trans_date  \\\n0      [tensor(0), tensor(7200), tensor(10800), tenso...   \n1      [tensor(0), tensor(18000), tensor(36000), tens...   \n2      [tensor(3600), tensor(7200), tensor(43200), te...   \n3      [tensor(14400), tensor(14400), tensor(14400), ...   \n4      [tensor(0), tensor(7200), tensor(21600), tenso...   \n...                                                  ...   \n29995  [tensor(3600), tensor(14400), tensor(14400), t...   \n29996  [tensor(0), tensor(3600), tensor(3600), tensor...   \n29997  [tensor(3600), tensor(3600), tensor(7200), ten...   \n29998  [tensor(3600), tensor(7200), tensor(10800), te...   \n29999  [tensor(57600), tensor(57600), tensor(57600), ...   \n\n                                      sourceB_event_time  \\\n0      [tensor(0), tensor(7200), tensor(10800), tenso...   \n1      [tensor(0), tensor(18000), tensor(36000), tens...   \n2      [tensor(3600), tensor(7200), tensor(43200), te...   \n3      [tensor(14400), tensor(14400), tensor(14400), ...   \n4      [tensor(0), tensor(7200), tensor(21600), tenso...   \n...                                                  ...   \n29995  [tensor(3600), tensor(14400), tensor(14400), t...   \n29996  [tensor(0), tensor(3600), tensor(3600), tensor...   \n29997  [tensor(3600), tensor(3600), tensor(7200), ten...   \n29998  [tensor(3600), tensor(7200), tensor(10800), te...   \n29999  [tensor(57600), tensor(57600), tensor(57600), ...   \n\n                                      sourceB_amount_rur  \n0      [tensor(10.2090, dtype=torch.float64), tensor(...  \n1      [tensor(4.0540, dtype=torch.float64), tensor(1...  \n2      [tensor(18.3190, dtype=torch.float64), tensor(...  \n3      [tensor(17.4020, dtype=torch.float64), tensor(...  \n4      [tensor(17.2510, dtype=torch.float64), tensor(...  \n...                                                  ...  \n29995  [tensor(78.8800, dtype=torch.float64), tensor(...  \n29996  [tensor(25.8770, dtype=torch.float64), tensor(...  \n29997  [tensor(215.6500, dtype=torch.float64), tensor...  \n29998  [tensor(32.1940, dtype=torch.float64), tensor(...  \n29999  [tensor(9.1130, dtype=torch.float64), tensor(3...  \n\n[30000 rows x 7 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>client_id</th>\n      <th>sourceA_trans_date</th>\n      <th>sourceA_event_time</th>\n      <th>sourceA_small_group</th>\n      <th>sourceB_trans_date</th>\n      <th>sourceB_event_time</th>\n      <th>sourceB_amount_rur</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4</td>\n      <td>[tensor(0), tensor(7200), tensor(10800), tenso...</td>\n      <td>[tensor(0), tensor(7200), tensor(10800), tenso...</td>\n      <td>[tensor(1), tensor(3), tensor(1), tensor(1), t...</td>\n      <td>[tensor(0), tensor(7200), tensor(10800), tenso...</td>\n      <td>[tensor(0), tensor(7200), tensor(10800), tenso...</td>\n      <td>[tensor(10.2090, dtype=torch.float64), tensor(...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>6</td>\n      <td>[tensor(0), tensor(18000), tensor(36000), tens...</td>\n      <td>[tensor(0), tensor(18000), tensor(36000), tens...</td>\n      <td>[tensor(4), tensor(3), tensor(1), tensor(3), t...</td>\n      <td>[tensor(0), tensor(18000), tensor(36000), tens...</td>\n      <td>[tensor(0), tensor(18000), tensor(36000), tens...</td>\n      <td>[tensor(4.0540, dtype=torch.float64), tensor(1...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7</td>\n      <td>[tensor(3600), tensor(7200), tensor(43200), te...</td>\n      <td>[tensor(3600), tensor(7200), tensor(43200), te...</td>\n      <td>[tensor(3), tensor(53), tensor(1), tensor(5), ...</td>\n      <td>[tensor(3600), tensor(7200), tensor(43200), te...</td>\n      <td>[tensor(3600), tensor(7200), tensor(43200), te...</td>\n      <td>[tensor(18.3190, dtype=torch.float64), tensor(...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10</td>\n      <td>[tensor(14400), tensor(14400), tensor(14400), ...</td>\n      <td>[tensor(14400), tensor(14400), tensor(14400), ...</td>\n      <td>[tensor(16), tensor(1), tensor(53), tensor(10)...</td>\n      <td>[tensor(14400), tensor(14400), tensor(14400), ...</td>\n      <td>[tensor(14400), tensor(14400), tensor(14400), ...</td>\n      <td>[tensor(17.4020, dtype=torch.float64), tensor(...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11</td>\n      <td>[tensor(0), tensor(7200), tensor(21600), tenso...</td>\n      <td>[tensor(0), tensor(7200), tensor(21600), tenso...</td>\n      <td>[tensor(3), tensor(9), tensor(1), tensor(1), t...</td>\n      <td>[tensor(0), tensor(7200), tensor(21600), tenso...</td>\n      <td>[tensor(0), tensor(7200), tensor(21600), tenso...</td>\n      <td>[tensor(17.2510, dtype=torch.float64), tensor(...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>29995</th>\n      <td>49993</td>\n      <td>[tensor(3600), tensor(14400), tensor(14400), t...</td>\n      <td>[tensor(3600), tensor(14400), tensor(14400), t...</td>\n      <td>[tensor(10), tensor(49), tensor(36), tensor(21...</td>\n      <td>[tensor(3600), tensor(14400), tensor(14400), t...</td>\n      <td>[tensor(3600), tensor(14400), tensor(14400), t...</td>\n      <td>[tensor(78.8800, dtype=torch.float64), tensor(...</td>\n    </tr>\n    <tr>\n      <th>29996</th>\n      <td>49995</td>\n      <td>[tensor(0), tensor(3600), tensor(3600), tensor...</td>\n      <td>[tensor(0), tensor(3600), tensor(3600), tensor...</td>\n      <td>[tensor(3), tensor(9), tensor(2), tensor(9), t...</td>\n      <td>[tensor(0), tensor(3600), tensor(3600), tensor...</td>\n      <td>[tensor(0), tensor(3600), tensor(3600), tensor...</td>\n      <td>[tensor(25.8770, dtype=torch.float64), tensor(...</td>\n    </tr>\n    <tr>\n      <th>29997</th>\n      <td>49996</td>\n      <td>[tensor(3600), tensor(3600), tensor(7200), ten...</td>\n      <td>[tensor(3600), tensor(3600), tensor(7200), ten...</td>\n      <td>[tensor(13), tensor(1), tensor(5), tensor(47),...</td>\n      <td>[tensor(3600), tensor(3600), tensor(7200), ten...</td>\n      <td>[tensor(3600), tensor(3600), tensor(7200), ten...</td>\n      <td>[tensor(215.6500, dtype=torch.float64), tensor...</td>\n    </tr>\n    <tr>\n      <th>29998</th>\n      <td>49997</td>\n      <td>[tensor(3600), tensor(7200), tensor(10800), te...</td>\n      <td>[tensor(3600), tensor(7200), tensor(10800), te...</td>\n      <td>[tensor(1), tensor(1), tensor(1), tensor(1), t...</td>\n      <td>[tensor(3600), tensor(7200), tensor(10800), te...</td>\n      <td>[tensor(3600), tensor(7200), tensor(10800), te...</td>\n      <td>[tensor(32.1940, dtype=torch.float64), tensor(...</td>\n    </tr>\n    <tr>\n      <th>29999</th>\n      <td>49998</td>\n      <td>[tensor(57600), tensor(57600), tensor(57600), ...</td>\n      <td>[tensor(57600), tensor(57600), tensor(57600), ...</td>\n      <td>[tensor(12), tensor(4), tensor(7), tensor(1), ...</td>\n      <td>[tensor(57600), tensor(57600), tensor(57600), ...</td>\n      <td>[tensor(57600), tensor(57600), tensor(57600), ...</td>\n      <td>[tensor(9.1130, dtype=torch.float64), tensor(3...</td>\n    </tr>\n  </tbody>\n</table>\n<p>30000 rows × 7 columns</p>\n</div>"},"metadata":{}}],"execution_count":19},{"id":"9f89fe5f-2e65-4d90-8b9a-222538f74bfc","cell_type":"code","source":"train_df, test_df = train_test_split(joined_data,\n                                     test_size=0.4,\n                                     random_state=42)\ntrain_df, valid_df = train_test_split(train_df,\n                                      test_size=0.1,\n                                      random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T16:34:28.795101Z","iopub.execute_input":"2025-05-08T16:34:28.795325Z","iopub.status.idle":"2025-05-08T16:34:28.818928Z","shell.execute_reply.started":"2025-05-08T16:34:28.795306Z","shell.execute_reply":"2025-05-08T16:34:28.817994Z"}},"outputs":[],"execution_count":20},{"id":"546903f8-6f88-4a25-9537-06afa93a954c","cell_type":"code","source":"train_df = train_df.reset_index(drop=True)\nvalid_df = valid_df.reset_index(drop=True)\ntest_df = test_df.reset_index(drop=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T16:34:28.819828Z","iopub.execute_input":"2025-05-08T16:34:28.820130Z","iopub.status.idle":"2025-05-08T16:34:28.830750Z","shell.execute_reply.started":"2025-05-08T16:34:28.820108Z","shell.execute_reply":"2025-05-08T16:34:28.830001Z"}},"outputs":[],"execution_count":21},{"id":"ae1f78f6-6ec6-489e-9ce8-b830a3e8657b","cell_type":"code","source":"train_dict = train_df.to_dict(\"records\")\nvalid_dict = valid_df.to_dict(\"records\")\ntest_dict = test_df.to_dict(\"records\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T16:34:28.831604Z","iopub.execute_input":"2025-05-08T16:34:28.831883Z","iopub.status.idle":"2025-05-08T16:34:28.995041Z","shell.execute_reply.started":"2025-05-08T16:34:28.831853Z","shell.execute_reply":"2025-05-08T16:34:28.994164Z"}},"outputs":[],"execution_count":22},{"id":"901e08dd-db96-42d0-b850-e1ab5dbfa0ff","cell_type":"code","source":"source_features = {\n    \"sourceA\": {\n        \"categorical\": [\"small_group\"],\n        \"numeric\": [],\n    },\n    \"sourceB\": {\n        \"categorical\": [],\n        \"numeric\": [\"amount_rur\"],\n    },\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T16:34:28.998533Z","iopub.execute_input":"2025-05-08T16:34:28.998748Z","iopub.status.idle":"2025-05-08T16:34:29.002439Z","shell.execute_reply.started":"2025-05-08T16:34:28.998729Z","shell.execute_reply":"2025-05-08T16:34:29.001530Z"}},"outputs":[],"execution_count":23},{"id":"ebe6998b-3e9a-4fd5-9ba6-388f2e983416","cell_type":"code","source":"inf_test_data = MultiModalInferenceIterableDataset(\n    data = test_dict,\n    source_features = source_features,\n    col_id = \"client_id\",\n    col_time = \"trans_date\",\n    source_names = (\"sourceA\", \"sourceB\")\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T16:34:29.003746Z","iopub.execute_input":"2025-05-08T16:34:29.003960Z","iopub.status.idle":"2025-05-08T16:34:29.014864Z","shell.execute_reply.started":"2025-05-08T16:34:29.003942Z","shell.execute_reply":"2025-05-08T16:34:29.014085Z"}},"outputs":[],"execution_count":24},{"id":"9931523f-1deb-4f5a-b292-aa112b2a0cb9","cell_type":"code","source":"inf_test_loader = DataLoader(\n    dataset = inf_test_data,\n    collate_fn = partial(inf_test_data.collate_fn, col_id=\"client_id\"),\n    shuffle = False,\n    num_workers = 0,\n    batch_size = 8\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T16:34:29.015828Z","iopub.execute_input":"2025-05-08T16:34:29.016123Z","iopub.status.idle":"2025-05-08T16:34:29.027221Z","shell.execute_reply.started":"2025-05-08T16:34:29.016094Z","shell.execute_reply":"2025-05-08T16:34:29.026585Z"}},"outputs":[],"execution_count":25},{"id":"2fea5913-06cd-44d8-b13e-946a731cb2eb","cell_type":"markdown","source":"## MY CODe","metadata":{}},{"id":"0fc679e5-45c7-4096-a0ef-fac34fa45605","cell_type":"code","source":"!git clone https://github.com/google-research/google-research.git","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T16:34:29.027977Z","iopub.execute_input":"2025-05-08T16:34:29.028192Z","iopub.status.idle":"2025-05-08T16:35:07.775053Z","shell.execute_reply.started":"2025-05-08T16:34:29.028172Z","shell.execute_reply":"2025-05-08T16:35:07.773888Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'google-research'...\nremote: Enumerating objects: 93586, done.\u001b[K\nremote: Counting objects: 100% (43/43), done.\u001b[K\nremote: Compressing objects: 100% (38/38), done.\u001b[K\nremote: Total 93586 (delta 14), reused 11 (delta 4), pack-reused 93543 (from 5)\u001b[K\nReceiving objects: 100% (93586/93586), 1.08 GiB | 44.65 MiB/s, done.\nResolving deltas: 100% (58488/58488), done.\nUpdating files: 100% (22188/22188), done.\n","output_type":"stream"}],"execution_count":26},{"id":"63ad2596-da46-4de1-8b97-2d89a983b392","cell_type":"code","source":"import sys\nsys.path.append(\"google-research/graph_embedding/metrics\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T16:35:07.776114Z","iopub.execute_input":"2025-05-08T16:35:07.776387Z","iopub.status.idle":"2025-05-08T16:35:07.780137Z","shell.execute_reply.started":"2025-05-08T16:35:07.776365Z","shell.execute_reply":"2025-05-08T16:35:07.779423Z"}},"outputs":[],"execution_count":27},{"id":"1cea746c-f5de-46f6-936b-3df3061b2326","cell_type":"code","source":"from metrics import (rankme,\n        coherence,\n        pseudo_condition_number,\n        alpha_req,\n        stable_rank,\n        ne_sum,\n        self_clustering)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T16:35:07.780996Z","iopub.execute_input":"2025-05-08T16:35:07.781280Z","iopub.status.idle":"2025-05-08T16:35:07.794566Z","shell.execute_reply.started":"2025-05-08T16:35:07.781250Z","shell.execute_reply":"2025-05-08T16:35:07.793804Z"}},"outputs":[],"execution_count":28},{"id":"26622396-c2bc-4975-a455-bf3265a44c6c","cell_type":"code","source":"!pip install git+https://github.com/simonzhang00/ripser-plusplus.git","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T16:35:07.795446Z","iopub.execute_input":"2025-05-08T16:35:07.795777Z","iopub.status.idle":"2025-05-08T16:35:42.299429Z","shell.execute_reply.started":"2025-05-08T16:35:07.795720Z","shell.execute_reply":"2025-05-08T16:35:42.298281Z"}},"outputs":[{"name":"stdout","text":"Collecting git+https://github.com/simonzhang00/ripser-plusplus.git\n  Cloning https://github.com/simonzhang00/ripser-plusplus.git to /tmp/pip-req-build-8uro2fa5\n  Running command git clone --filter=blob:none --quiet https://github.com/simonzhang00/ripser-plusplus.git /tmp/pip-req-build-8uro2fa5\n  Resolved https://github.com/simonzhang00/ripser-plusplus.git to commit 30243c0c752de26d7fdf6e41f08bf7b840ca4744\n  Running command git submodule update --init --recursive -q\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from ripserplusplus==1.1.3) (3.31.2)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ripserplusplus==1.1.3) (1.26.4)\nRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from ripserplusplus==1.1.3) (1.13.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->ripserplusplus==1.1.3) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->ripserplusplus==1.1.3) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->ripserplusplus==1.1.3) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->ripserplusplus==1.1.3) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->ripserplusplus==1.1.3) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->ripserplusplus==1.1.3) (2.4.1)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->ripserplusplus==1.1.3) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->ripserplusplus==1.1.3) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->ripserplusplus==1.1.3) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->ripserplusplus==1.1.3) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->ripserplusplus==1.1.3) (2024.2.0)\nBuilding wheels for collected packages: ripserplusplus\n  Building wheel for ripserplusplus (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for ripserplusplus: filename=ripserplusplus-1.1.3-cp310-cp310-linux_x86_64.whl size=571119 sha256=b360e00e468b593786939876d417a291cb07f56a2bd83b17dc074b574e70e7d4\n  Stored in directory: /tmp/pip-ephem-wheel-cache-hgub9mqy/wheels/0e/ba/fa/b0e13a51d380910fa3550fe884e5899867be8161c9e7f4bc8e\nSuccessfully built ripserplusplus\nInstalling collected packages: ripserplusplus\nSuccessfully installed ripserplusplus-1.1.3\n","output_type":"stream"}],"execution_count":29},{"id":"3acfe40f-5636-40b4-8916-56878eac40c1","cell_type":"code","source":"import ripserplusplus as rpp\ndef ripser_metric(embeddings):\n    \"\"\"Вычисление метрики на основе ripserplusplus.\"\"\"\n    start_time = time()  # Засекаем время\n    \n    if not isinstance(embeddings, np.ndarray):\n        embeddings = np.array(embeddings)\n\n    # Используем rpp.run с указанием режима обработки\n    diagrams = rpp.run(\"--format point-cloud\", embeddings)\n\n    # Пример вычисления: суммируем длины всех \"жизненных циклов\" из диаграммы\n    persistence_sum = sum([birth - death for birth, death in diagrams[0] if death > birth])\n\n    elapsed_time = time() - start_time  # Вычисляем время\n    # print(f\"Computed ripser metric in {elapsed_time:.4f} seconds\")\n\n    return persistence_sum, elapsed_time","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T16:35:42.300712Z","iopub.execute_input":"2025-05-08T16:35:42.301051Z","iopub.status.idle":"2025-05-08T16:35:42.312151Z","shell.execute_reply.started":"2025-05-08T16:35:42.301026Z","shell.execute_reply":"2025-05-08T16:35:42.311271Z"}},"outputs":[],"execution_count":30},{"id":"1b832a19-eb6d-4968-b7e7-84856ff80d11","cell_type":"code","source":"def create_datasets(train_dict, valid_dict, params, source_features):\n    splitter = SampleSlices(\n        split_count=params[\"split_count\"],\n        cnt_min=params[\"cnt_min\"],\n        cnt_max=params[\"cnt_max\"],\n    )\n\n    train_data = MultiModalIterableDataset(\n        data=train_dict,\n        splitter=splitter,\n        source_features=source_features,\n        col_id=\"client_id\",\n        col_time=\"trans_date\",\n        source_names=(\"sourceA\", \"sourceB\"),\n    )\n\n    valid_data = MultiModalIterableDataset(\n        data=valid_dict,\n        splitter=splitter,\n        source_features=source_features,\n        col_id=\"client_id\",\n        col_time=\"trans_date\",\n        source_names=(\"sourceA\", \"sourceB\"),\n    )\n\n    data_loader = PtlsDataModule(\n        train_data=train_data,\n        train_batch_size=params[\"batch_size\"],\n        train_num_workers=0,\n        valid_data=valid_data,\n    )\n\n    return data_loader","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T16:35:42.313137Z","iopub.execute_input":"2025-05-08T16:35:42.313447Z","iopub.status.idle":"2025-05-08T16:35:42.330080Z","shell.execute_reply.started":"2025-05-08T16:35:42.313425Z","shell.execute_reply":"2025-05-08T16:35:42.329299Z"}},"outputs":[],"execution_count":31},{"id":"3c308cd5-1e80-4cf8-ba00-4858ea2aed98","cell_type":"code","source":"def compute_metrics(model, pl_trainer, inf_test_loader, selected_metrics=None, n_samples=10, sample_fraction=1/20):\n    import gc\n    from sklearn.utils import resample\n    from time import time\n\n    model.eval()\n    inference_module = InferenceModuleMultimodal(\n        model=model,\n        pandas_output=True,\n        drop_seq_features=True,\n        model_out_name=\"emb\",\n        col_id=\"client_id\",\n    )\n    inference_module.model.is_reduce_sequence = True\n\n    # Получение эмбеддингов\n    inf_test_embeddings = pd.concat(\n        pl_trainer.predict(inference_module, inf_test_loader),\n        axis=0,\n    )\n    embeddings_np = inf_test_embeddings.drop(columns=[\"client_id\"]).to_numpy(dtype=np.float32)\n    sample_size = max(1, int(sample_fraction * embeddings_np.shape[0]))\n\n    # Метрики\n    available_metrics = {\n        \"rankme\": rankme,\n        \"coherence\": coherence,\n        \"pseudo_condition_number\": pseudo_condition_number,\n        \"alpha_req\": alpha_req,\n        \"stable_rank\": stable_rank,\n        \"ne_sum\": ne_sum,\n        \"self_clustering\": self_clustering,\n        \"ripser\": ripser_metric\n    }\n    if selected_metrics is None:\n        selected_metrics = list(available_metrics.keys())\n\n    metrics = {name: [] for name in selected_metrics}\n    times = {name: [] for name in selected_metrics}\n\n    for i in range(n_samples):\n        sample = resample(embeddings_np, n_samples=sample_size, replace=False, random_state=42 + i)\n        u, s, _ = np.linalg.svd(sample, compute_uv=True, full_matrices=False)\n\n        for metric_name in selected_metrics:\n            if metric_name not in available_metrics:\n                continue\n\n            try:\n                if metric_name == \"ripser\":\n                    val, t = available_metrics[metric_name](sample)\n                else:\n                    t0 = time()\n                    val = available_metrics[metric_name](sample, u=u, s=s)\n                    t = time() - t0\n\n                metrics[metric_name].append(val)\n                times[metric_name].append(t)\n            except Exception as e:\n                print(f\"⚠️ Failed to compute {metric_name} on sample {i}: {e}\")\n\n        gc.collect()\n\n    averaged_metrics = {k: np.mean(v) for k, v in metrics.items()}\n    std_metrics = {k: np.std(v) for k, v in metrics.items()}\n    \n    averaged_times = {k: np.mean(v) for k, v in times.items()}\n    std_times = {k: np.std(v) for k, v in times.items()}\n\n    print(\"\\n📊 Средние значения метрик и время вычисления:\")\n    for metric_name in averaged_metrics:\n        metric_value = averaged_metrics[metric_name]\n        metric_time = averaged_times.get(metric_name, None)\n        print(f\"🧠 {metric_name:30s} = {metric_value:.4f} | ⏱ {metric_time:.4f} сек\")\n\n    return averaged_metrics, averaged_times, std_metrics, std_times, inf_test_embeddings\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T16:35:42.331128Z","iopub.execute_input":"2025-05-08T16:35:42.331434Z","iopub.status.idle":"2025-05-08T16:35:42.347962Z","shell.execute_reply.started":"2025-05-08T16:35:42.331406Z","shell.execute_reply":"2025-05-08T16:35:42.347088Z"}},"outputs":[],"execution_count":32},{"id":"d5afba88-ca89-4002-9e51-73f0c90458ec","cell_type":"code","source":"import catboost\n\n\ndef evaluate_model(model, pl_trainer, checkpoint=None, selected_metrics=None, topk=5):\n    model.eval()\n    metrics, times, std_metrics, std_times, inf_test_embeddings = compute_metrics(model, pl_trainer, inf_test_loader, selected_metrics)\n    targets_df = df_target.set_index(\"client_id\")\n    inf_test_df = inf_test_embeddings.merge(targets_df, how=\"inner\", on=\"client_id\").set_index(\"client_id\")\n    \n    X = inf_test_df.drop(columns=[\"bins\"])\n    y = inf_test_df[\"bins\"]\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n    \n    classifier = catboost.CatBoostClassifier(\n        iterations=150,\n        random_seed=42,\n        verbose=0,\n    )\n    classifier.fit(X_train, y_train)\n    \n    accuracy = classifier.score(X_test, y_test)\n\n    del classifier\n    \n    return metrics, times, std_metrics, std_times, accuracy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T16:35:42.349120Z","iopub.execute_input":"2025-05-08T16:35:42.349465Z","iopub.status.idle":"2025-05-08T16:35:42.376175Z","shell.execute_reply.started":"2025-05-08T16:35:42.349433Z","shell.execute_reply":"2025-05-08T16:35:42.375492Z"}},"outputs":[],"execution_count":33},{"id":"c9423ffb-c641-49da-922a-f99f310a5420","cell_type":"code","source":"fixed_params = {\n    \"batch_size\": 64,\n    \"learning_rate\": 0.001,\n    \"split_count\": 3,\n    \"cnt_min\": 10,\n    \"cnt_max\": 50,\n    \"embedding_dim\": 16,  # Размерность эмбеддингов\n    \"category_embedding_dim\": 8,  # Размерность категорий эмбеддингов\n    \"hidden_size\": 128,  # Размер скрытого слоя по умолчанию\n}\n\n# Список гиперпараметров для перебора\nvariable_params = {\n    \"batch_size\": [16, 32, 64, 128], \n    \"learning_rate\": [0.0001, 0.001, 0.05],\n    \"split_count\": [2, 3, 5],\n    \"cnt_min\": [5, 10, 20],\n    \"cnt_max\": [50, 80, 100],\n    \"embedding_dim\": [8, 16, 32],\n    \"category_embedding_dim\": [8, 16, 24],\n    \"hidden_size\": [64, 128, 256, 1024],\n}\n\n# Создание списка всех гиперпараметров, которые нужно перебрать\nall_hyperparameter_grids = []\nfor variable_param_name, variable_param_values in variable_params.items():\n    for value in variable_param_values:\n        hyperparameter_grid = {**fixed_params, variable_param_name: value}\n        all_hyperparameter_grids.append((variable_param_name, hyperparameter_grid))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T16:35:42.377011Z","iopub.execute_input":"2025-05-08T16:35:42.377297Z","iopub.status.idle":"2025-05-08T16:35:42.392340Z","shell.execute_reply.started":"2025-05-08T16:35:42.377272Z","shell.execute_reply":"2025-05-08T16:35:42.391517Z"}},"outputs":[],"execution_count":34},{"id":"32ff8195-6bc8-45f6-af73-0b9a4dd5a8c3","cell_type":"code","source":"metric_names = [\n    \"rankme\", \"coherence\", \"pseudo_condition_number\",\n    \"alpha_req\", \"stable_rank\", \"ne_sum\", \"self_clustering\", \"ripser\"\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T16:35:42.393096Z","iopub.execute_input":"2025-05-08T16:35:42.393448Z","iopub.status.idle":"2025-05-08T16:35:42.408001Z","shell.execute_reply.started":"2025-05-08T16:35:42.393422Z","shell.execute_reply":"2025-05-08T16:35:42.406946Z"}},"outputs":[],"execution_count":35},{"id":"7ca1115d-c16e-4c72-a7c6-31d5f9f098dc","cell_type":"code","source":"category_embedding_dims = {\n    \"small_group\": (150, fixed_params[\"category_embedding_dim\"]),\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T16:35:42.408913Z","iopub.execute_input":"2025-05-08T16:35:42.409215Z","iopub.status.idle":"2025-05-08T16:35:42.423811Z","shell.execute_reply.started":"2025-05-08T16:35:42.409178Z","shell.execute_reply":"2025-05-08T16:35:42.422885Z"}},"outputs":[],"execution_count":36},{"id":"ad25eb4a-0a4e-4cd6-9d6b-3e38d3cc3faa","cell_type":"code","source":"import os","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T16:35:42.424801Z","iopub.execute_input":"2025-05-08T16:35:42.425038Z","iopub.status.idle":"2025-05-08T16:35:42.437450Z","shell.execute_reply.started":"2025-05-08T16:35:42.425018Z","shell.execute_reply":"2025-05-08T16:35:42.436581Z"}},"outputs":[],"execution_count":37},{"id":"150285f7-e90d-4a43-bc9c-ebe88839196c","cell_type":"code","source":"checkpoints_path = \"checkpoints\"\nos.makedirs(checkpoints_path, exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T16:35:42.437982Z","iopub.execute_input":"2025-05-08T16:35:42.438219Z","iopub.status.idle":"2025-05-08T16:35:42.454998Z","shell.execute_reply.started":"2025-05-08T16:35:42.438200Z","shell.execute_reply":"2025-05-08T16:35:42.454182Z"}},"outputs":[],"execution_count":38},{"id":"7abe764b-1033-4e80-ac36-a01ea8af5eb8","cell_type":"code","source":"splitter = SampleSlices(split_count=5, cnt_min=25, cnt_max=50)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T16:35:42.456086Z","iopub.execute_input":"2025-05-08T16:35:42.456422Z","iopub.status.idle":"2025-05-08T16:35:42.467608Z","shell.execute_reply.started":"2025-05-08T16:35:42.456393Z","shell.execute_reply":"2025-05-08T16:35:42.466757Z"}},"outputs":[],"execution_count":39},{"id":"40fce490-8628-4ddb-a0de-88a504127673","cell_type":"code","source":"class CustomLogger(pl.Callback):\n    def __init__(self):\n        super().__init__()\n        self.early_stopping_epoch = None  # Запомним, на какой эпохе произошла остановка\n    \n    def on_train_epoch_end(self, trainer, pl_module):\n        train_loss = trainer.callback_metrics.get(\"train_loss\", None)\n        val_loss = trainer.callback_metrics.get(\"val_loss\", None)\n        \n        if train_loss is not None and val_loss is not None:\n            print(f\"Epoch {trainer.current_epoch}: Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n        \n        # Если валидационный лосс увеличивается - фиксируем эпоху остановки\n        if trainer.early_stopping_callback is not None and trainer.early_stopping_callback.wait_count == 0:\n            self.early_stopping_epoch = trainer.current_epoch\n\n\ncustom_logger = CustomLogger()\nearly_stopping_callback = EarlyStopping(\n    monitor=\"val_loss\",\n    patience=5,\n    mode=\"min\",\n    verbose=True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T16:35:42.468599Z","iopub.execute_input":"2025-05-08T16:35:42.468879Z","iopub.status.idle":"2025-05-08T16:35:42.480054Z","shell.execute_reply.started":"2025-05-08T16:35:42.468850Z","shell.execute_reply":"2025-05-08T16:35:42.479198Z"}},"outputs":[],"execution_count":40},{"id":"1540f7bd-56fe-402f-81e9-f7761c272a6b","cell_type":"code","source":"! rm -rf /kaggle/working/checkpoints","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T16:35:42.480897Z","iopub.execute_input":"2025-05-08T16:35:42.481195Z","iopub.status.idle":"2025-05-08T16:35:42.639784Z","shell.execute_reply.started":"2025-05-08T16:35:42.481168Z","shell.execute_reply":"2025-05-08T16:35:42.638694Z"}},"outputs":[],"execution_count":41},{"id":"45b5a2f0-27bb-4f76-8eef-e9db0dc3b038","cell_type":"code","source":"! rm /kaggle/working/age_tr_params_tun_full.csv","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T16:35:42.641050Z","iopub.execute_input":"2025-05-08T16:35:42.641405Z","iopub.status.idle":"2025-05-08T16:35:42.793201Z","shell.execute_reply.started":"2025-05-08T16:35:42.641373Z","shell.execute_reply":"2025-05-08T16:35:42.792151Z"}},"outputs":[{"name":"stdout","text":"rm: cannot remove '/kaggle/working/age_tr_params_tun_full.csv': No such file or directory\n","output_type":"stream"}],"execution_count":42},{"id":"7f3a299f-0870-4455-b906-3c943c2fd927","cell_type":"code","source":"num_epochs = 30\noutput_csv = \"age_tr_params_tun_full.csv\"\n\n\nmetric_keys = [\n    \"rankme\", \"coherence\", \"pseudo_condition_number\", \n    \"alpha_req\", \"stable_rank\", \"ne_sum\", \"self_clustering\", \"ripser\"\n]\n\ncolumns = (\n    list(fixed_params.keys()) +\n    [\"checkpoint\", \"epoch_num\", \"accuracy\", \"early_stop_epoch\", \"hidden_size\"] +\n    [f\"metric_{k}\" for k in metric_keys] +\n    [f\"std_metric_{k}\" for k in metric_keys] +\n    [f\"time_{k}\" for k in metric_keys] +\n    [f\"std_time_{k}\" for k in metric_keys]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T16:35:42.794467Z","iopub.execute_input":"2025-05-08T16:35:42.794885Z","iopub.status.idle":"2025-05-08T16:35:42.800107Z","shell.execute_reply.started":"2025-05-08T16:35:42.794851Z","shell.execute_reply":"2025-05-08T16:35:42.799141Z"}},"outputs":[],"execution_count":43},{"id":"74305632-67ed-4eb6-aeeb-bb8f4fa57a56","cell_type":"code","source":"from time import time\nimport os\nimport gc\nimport torch\nimport pandas as pd\nimport glob\nfrom pytorch_lightning import Trainer\nfrom pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\nfrom functools import partial\n\ncur_time = time()\n\nfor param in all_hyperparameter_grids:\n    \n    print(f'All params are frozen except {param[0]}')\n    params = param[1]\n    # print(f\"Testing parameters: {params}\")\n\n    train_loader = create_datasets(train_dict, valid_dict, params, source_features)\n\n    sourceA_encoder_params = dict(\n        embeddings_noise=0.003,\n        linear_projection_size=64,\n        embeddings={\n            \"small_group\": {\"in\": len(np.unique(sourceA['small_group'])), \"out\": 32}\n        },\n    )\n    \n    sourceB_encoder_params = dict(\n        embeddings_noise=0.003,\n        linear_projection_size=64,\n        numeric_values={\"amount_rur\": \"identity\"},\n    )\n    \n    sourceA_encoder = TrxEncoder(**sourceA_encoder_params)\n    sourceB_encoder = TrxEncoder(**sourceB_encoder_params)\n    \n    seq_encoder = MultiModalSortTimeSeqEncoderContainer(\n        trx_encoders={\n            \"sourceA\": sourceA_encoder,\n            \"sourceB\": sourceB_encoder,\n        },\n        input_size=64,\n        hidden_size=params[\"hidden_size\"],  # Используем только текущее значение hidden_size\n        seq_encoder_cls=RnnEncoder,\n        type=\"gru\",\n    )\n\n    model = CoLESModule(\n        seq_encoder=seq_encoder,\n        optimizer_partial=partial(torch.optim.Adam, lr=params[\"learning_rate\"]),\n        lr_scheduler_partial=partial(torch.optim.lr_scheduler.StepLR, step_size=10, gamma=0.5),\n    )\n\n    early_stopping_callback = EarlyStopping(\n        monitor=\"loss\",\n        patience=5,\n        mode=\"min\",\n        verbose=True\n    )\n\n    checkpoint_callback = ModelCheckpoint(\n        dirpath=checkpoints_path,\n        filename=f\"model_{params['batch_size']}_{params['learning_rate']}_{params['split_count']}_{params['cnt_min']}_{params['cnt_max']}_{params['hidden_size']}{{epoch:02d}}\",\n        save_top_k=-1,\n        every_n_epochs=1,\n    )\n\n    # Обучение модели\n    pl_trainer = pl.Trainer(\n        callbacks=[checkpoint_callback, early_stopping_callback, custom_logger],\n        default_root_dir=checkpoints_path,\n        check_val_every_n_epoch=1,\n        max_epochs= num_epochs,\n        accelerator=\"gpu\",\n        devices=1,\n        enable_progress_bar=True,\n        precision=16\n    )\n    model.train()\n    pl_trainer.fit(model, train_loader)\n\n    early_stop_epoch = getattr(custom_logger, \"early_stopping_epoch\", None) or num_epochs\n\n    # Обработка чекпоинтов\n    checkpoint_files = glob.glob(f\"{checkpoints_path}/model_{params['batch_size']}_{params['learning_rate']}_{params['split_count']}_{params['cnt_min']}_{params['cnt_max']}_{params['hidden_size']}*.ckpt\")\n    checkpoint_files.sort()\n    print(f\"Elapsed time: {time() - cur_time:.2f} seconds\")\n\n    print(f'Early stop is {early_stop_epoch}')\n\n    for i, checkpoint in enumerate(checkpoint_files):\n        print(f\"Processing checkpoint number {i}\")\n        model = CoLESModule.load_from_checkpoint(checkpoint, seq_encoder=seq_encoder)\n    \n        # Вычисление метрик, времени, дисперсий и accuracy\n        metrics, times, std_metrics, std_times, accuracy = evaluate_model(model, pl_trainer, checkpoint)\n    \n        # Преобразование результатов в плоские словари\n        metrics_flattened = {f\"metric_{k}\": round(v, 4) for k, v in metrics.items()}\n        std_metrics_flattened = {f\"std_metric_{k}\": round(v, 4) for k, v in std_metrics.items()}\n        times_flattened = {f\"time_{k}\": round(v, 4) for k, v in times.items()}\n        std_times_flattened = {f\"std_time_{k}\": round(v, 4) for k, v in std_times.items()}\n    \n        # Сбор всех результатов\n        new_result = {\n            **params,\n            \"checkpoint\": checkpoint,\n            \"epoch_num\": int(i),\n            \"accuracy\": accuracy,\n            \"early_stop_epoch\": int(early_stop_epoch),\n            **metrics_flattened,\n            **std_metrics_flattened,\n            **times_flattened,\n            **std_times_flattened,\n        }\n    \n        # Сохранение в CSV\n        results = pd.DataFrame([new_result], columns=columns)\n        print('----------')\n        print(results[\"early_stop_epoch\"])\n\n        if not os.path.exists(output_csv):  \n            pd.DataFrame(columns=columns).to_csv(output_csv, mode=\"w\", index=False, header=True)\n        \n        results.to_csv(output_csv, mode=\"a\", header=False, index=False)\n\n        del metrics, accuracy, new_result\n        torch.cuda.empty_cache()\n        gc.collect()\n\n    print(f\"Removing checkpoints for parameters: {params}\")\n    for checkpoint in checkpoint_files:\n        os.remove(checkpoint)\n\n    del model\n    del train_loader\n    torch.cuda.empty_cache()\n    gc.collect()\n\nprint(\"Optimization complete!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T16:35:42.801039Z","iopub.execute_input":"2025-05-08T16:35:42.801311Z","execution_failed":"2025-05-08T18:49:55.654Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"All params are frozen except batch_size\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/lightning_fabric/connector.py:572: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n/usr/local/lib/python3.10/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints exists and is not empty.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Sanity Checking: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/data.py:123: Your `IterableDataset` has `__len__` defined. In combination with multi-process data loading (when num_workers > 1), `__len__` could be inaccurate if each worker is not configured independently to avoid having duplicate data.\n/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"755d3147003c44928e8aec0085cb64f0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Elapsed time: 1575.08 seconds\nEarly stop is 13\nProcessing checkpoint number 0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Predicting: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4209134b6de54e85b27aabd0d3e88762"}},"metadata":{}},{"name":"stdout","text":"\n📊 Средние значения метрик и время вычисления:\n🧠 rankme                         = 32.7402 | ⏱ 0.0005 сек\n🧠 coherence                      = 2.6043 | ⏱ 0.0001 сек\n🧠 pseudo_condition_number        = 0.0002 | ⏱ 0.0000 сек\n🧠 alpha_req                      = 4.4834 | ⏱ 0.0009 сек\n🧠 stable_rank                    = 1.1218 | ⏱ 0.0011 сек\n🧠 ne_sum                         = 6.0793 | ⏱ 0.0028 сек\n🧠 self_clustering                = 0.7945 | ⏱ 0.0036 сек\n🧠 ripser                         = -947.8171 | ⏱ 0.1968 сек\n----------\n0    13\nName: early_stop_epoch, dtype: int64\nProcessing checkpoint number 1\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/data.py:123: Your `IterableDataset` has `__len__` defined. In combination with multi-process data loading (when num_workers > 1), `__len__` could be inaccurate if each worker is not configured independently to avoid having duplicate data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Predicting: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"668d91554d7a4c1c8dfd3496f817c438"}},"metadata":{}},{"name":"stdout","text":"\n📊 Средние значения метрик и время вычисления:\n🧠 rankme                         = 33.6655 | ⏱ 0.0001 сек\n🧠 coherence                      = 2.5661 | ⏱ 0.0001 сек\n🧠 pseudo_condition_number        = 0.0001 | ⏱ 0.0000 сек\n🧠 alpha_req                      = 5.0806 | ⏱ 0.0002 сек\n🧠 stable_rank                    = 1.1165 | ⏱ 0.0001 сек\n🧠 ne_sum                         = 6.6947 | ⏱ 0.0016 сек\n🧠 self_clustering                = 0.8017 | ⏱ 0.0013 сек\n🧠 ripser                         = -1140.3339 | ⏱ 0.2103 сек\n----------\n0    13\nName: early_stop_epoch, dtype: int64\nProcessing checkpoint number 2\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/data.py:123: Your `IterableDataset` has `__len__` defined. In combination with multi-process data loading (when num_workers > 1), `__len__` could be inaccurate if each worker is not configured independently to avoid having duplicate data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Predicting: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e457be09f4ec40d2a578f8f70d993a23"}},"metadata":{}},{"name":"stdout","text":"\n📊 Средние значения метрик и время вычисления:\n🧠 rankme                         = 37.0487 | ⏱ 0.0001 сек\n🧠 coherence                      = 2.5964 | ⏱ 0.0001 сек\n🧠 pseudo_condition_number        = 0.0001 | ⏱ 0.0000 сек\n🧠 alpha_req                      = 5.4424 | ⏱ 0.0002 сек\n🧠 stable_rank                    = 1.1293 | ⏱ 0.0001 сек\n🧠 ne_sum                         = 6.7690 | ⏱ 0.0017 сек\n🧠 self_clustering                = 0.7835 | ⏱ 0.0013 сек\n🧠 ripser                         = -1275.9854 | ⏱ 0.2026 сек\n----------\n0    13\nName: early_stop_epoch, dtype: int64\nProcessing checkpoint number 3\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/data.py:123: Your `IterableDataset` has `__len__` defined. In combination with multi-process data loading (when num_workers > 1), `__len__` could be inaccurate if each worker is not configured independently to avoid having duplicate data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Predicting: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a04321d75acc4dbabad9ee1f136a1422"}},"metadata":{}},{"name":"stdout","text":"\n📊 Средние значения метрик и время вычисления:\n🧠 rankme                         = 38.6520 | ⏱ 0.0001 сек\n🧠 coherence                      = 3.1949 | ⏱ 0.0001 сек\n🧠 pseudo_condition_number        = 0.0000 | ⏱ 0.0000 сек\n🧠 alpha_req                      = 5.8872 | ⏱ 0.0002 сек\n🧠 stable_rank                    = 1.1408 | ⏱ 0.0001 сек\n🧠 ne_sum                         = 7.5240 | ⏱ 0.0017 сек\n🧠 self_clustering                = 0.7675 | ⏱ 0.0013 сек\n🧠 ripser                         = -1369.1481 | ⏱ 0.2101 сек\n----------\n0    13\nName: early_stop_epoch, dtype: int64\nProcessing checkpoint number 4\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/data.py:123: Your `IterableDataset` has `__len__` defined. In combination with multi-process data loading (when num_workers > 1), `__len__` could be inaccurate if each worker is not configured independently to avoid having duplicate data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Predicting: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f8f76c54703c486ea95e81bee54a4e0a"}},"metadata":{}},{"name":"stdout","text":"\n📊 Средние значения метрик и время вычисления:\n🧠 rankme                         = 39.7327 | ⏱ 0.0001 сек\n🧠 coherence                      = 3.5537 | ⏱ 0.0001 сек\n🧠 pseudo_condition_number        = 0.0000 | ⏱ 0.0000 сек\n🧠 alpha_req                      = 5.8200 | ⏱ 0.0002 сек\n🧠 stable_rank                    = 1.1480 | ⏱ 0.0001 сек\n🧠 ne_sum                         = 6.7314 | ⏱ 0.0017 сек\n🧠 self_clustering                = 0.7580 | ⏱ 0.0013 сек\n🧠 ripser                         = -1439.8890 | ⏱ 0.2078 сек\n----------\n0    13\nName: early_stop_epoch, dtype: int64\nProcessing checkpoint number 5\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/data.py:123: Your `IterableDataset` has `__len__` defined. In combination with multi-process data loading (when num_workers > 1), `__len__` could be inaccurate if each worker is not configured independently to avoid having duplicate data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Predicting: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4688f152e0a423290a29bc0eac31635"}},"metadata":{}},{"name":"stdout","text":"\n📊 Средние значения метрик и время вычисления:\n🧠 rankme                         = 39.5207 | ⏱ 0.0001 сек\n🧠 coherence                      = 3.7222 | ⏱ 0.0001 сек\n🧠 pseudo_condition_number        = 0.0000 | ⏱ 0.0000 сек\n🧠 alpha_req                      = 6.1096 | ⏱ 0.0002 сек\n🧠 stable_rank                    = 1.1472 | ⏱ 0.0001 сек\n🧠 ne_sum                         = 6.3859 | ⏱ 0.0017 сек\n🧠 self_clustering                = 0.7592 | ⏱ 0.0013 сек\n🧠 ripser                         = -1450.8501 | ⏱ 0.2022 сек\n----------\n0    13\nName: early_stop_epoch, dtype: int64\nProcessing checkpoint number 6\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/data.py:123: Your `IterableDataset` has `__len__` defined. In combination with multi-process data loading (when num_workers > 1), `__len__` could be inaccurate if each worker is not configured independently to avoid having duplicate data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Predicting: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f5d9371c73d4b7ead16ca2d52520067"}},"metadata":{}},{"name":"stdout","text":"\n📊 Средние значения метрик и время вычисления:\n🧠 rankme                         = 40.5403 | ⏱ 0.0001 сек\n🧠 coherence                      = 4.2413 | ⏱ 0.0001 сек\n🧠 pseudo_condition_number        = 0.0000 | ⏱ 0.0000 сек\n🧠 alpha_req                      = 6.2536 | ⏱ 0.0002 сек\n🧠 stable_rank                    = 1.1479 | ⏱ 0.0001 сек\n🧠 ne_sum                         = 6.6611 | ⏱ 0.0016 сек\n🧠 self_clustering                = 0.7577 | ⏱ 0.0012 сек\n🧠 ripser                         = -1497.8190 | ⏱ 0.2046 сек\n----------\n0    13\nName: early_stop_epoch, dtype: int64\nProcessing checkpoint number 7\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/data.py:123: Your `IterableDataset` has `__len__` defined. In combination with multi-process data loading (when num_workers > 1), `__len__` could be inaccurate if each worker is not configured independently to avoid having duplicate data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Predicting: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77f696ba04db474fb1ffe248a9de53a4"}},"metadata":{}},{"name":"stdout","text":"\n📊 Средние значения метрик и время вычисления:\n🧠 rankme                         = 39.9676 | ⏱ 0.0001 сек\n🧠 coherence                      = 4.3002 | ⏱ 0.0001 сек\n🧠 pseudo_condition_number        = 0.0000 | ⏱ 0.0000 сек\n🧠 alpha_req                      = 6.4580 | ⏱ 0.0002 сек\n🧠 stable_rank                    = 1.1505 | ⏱ 0.0001 сек\n🧠 ne_sum                         = 6.2918 | ⏱ 0.0017 сек\n🧠 self_clustering                = 0.7542 | ⏱ 0.0013 сек\n🧠 ripser                         = -1489.6116 | ⏱ 0.1995 сек\n----------\n0    13\nName: early_stop_epoch, dtype: int64\nProcessing checkpoint number 8\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/data.py:123: Your `IterableDataset` has `__len__` defined. In combination with multi-process data loading (when num_workers > 1), `__len__` could be inaccurate if each worker is not configured independently to avoid having duplicate data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Predicting: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"634366134f6148eb9dbf08b7fab50b20"}},"metadata":{}},{"name":"stdout","text":"\n📊 Средние значения метрик и время вычисления:\n🧠 rankme                         = 39.2196 | ⏱ 0.0001 сек\n🧠 coherence                      = 4.2326 | ⏱ 0.0001 сек\n🧠 pseudo_condition_number        = 0.0000 | ⏱ 0.0000 сек\n🧠 alpha_req                      = 6.4494 | ⏱ 0.0002 сек\n🧠 stable_rank                    = 1.1374 | ⏱ 0.0001 сек\n🧠 ne_sum                         = 6.3341 | ⏱ 0.0017 сек\n🧠 self_clustering                = 0.7719 | ⏱ 0.0012 сек\n🧠 ripser                         = -1467.2506 | ⏱ 0.2020 сек\n----------\n0    13\nName: early_stop_epoch, dtype: int64\nProcessing checkpoint number 9\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/data.py:123: Your `IterableDataset` has `__len__` defined. In combination with multi-process data loading (when num_workers > 1), `__len__` could be inaccurate if each worker is not configured independently to avoid having duplicate data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Predicting: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c16e7173a2649d7bc4789414295e68c"}},"metadata":{}},{"name":"stdout","text":"\n📊 Средние значения метрик и время вычисления:\n🧠 rankme                         = 37.5882 | ⏱ 0.0001 сек\n🧠 coherence                      = 3.9486 | ⏱ 0.0001 сек\n🧠 pseudo_condition_number        = 0.0000 | ⏱ 0.0000 сек\n🧠 alpha_req                      = 6.6377 | ⏱ 0.0002 сек\n🧠 stable_rank                    = 1.1276 | ⏱ 0.0001 сек\n🧠 ne_sum                         = 6.6781 | ⏱ 0.0017 сек\n🧠 self_clustering                = 0.7857 | ⏱ 0.0013 сек\n🧠 ripser                         = -1440.1417 | ⏱ 0.2033 сек\n----------\n0    13\nName: early_stop_epoch, dtype: int64\nProcessing checkpoint number 10\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/data.py:123: Your `IterableDataset` has `__len__` defined. In combination with multi-process data loading (when num_workers > 1), `__len__` could be inaccurate if each worker is not configured independently to avoid having duplicate data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Predicting: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fcd77bc5590d4e5a85dc42e8bc8d1411"}},"metadata":{}},{"name":"stdout","text":"\n📊 Средние значения метрик и время вычисления:\n🧠 rankme                         = 40.7443 | ⏱ 0.0001 сек\n🧠 coherence                      = 4.1878 | ⏱ 0.0001 сек\n🧠 pseudo_condition_number        = 0.0000 | ⏱ 0.0000 сек\n🧠 alpha_req                      = 6.2156 | ⏱ 0.0002 сек\n🧠 stable_rank                    = 1.1475 | ⏱ 0.0001 сек\n🧠 ne_sum                         = 6.7339 | ⏱ 0.0017 сек\n🧠 self_clustering                = 0.7584 | ⏱ 0.0013 сек\n🧠 ripser                         = -1504.5659 | ⏱ 0.1899 сек\n----------\n0    13\nName: early_stop_epoch, dtype: int64\nProcessing checkpoint number 11\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/data.py:123: Your `IterableDataset` has `__len__` defined. In combination with multi-process data loading (when num_workers > 1), `__len__` could be inaccurate if each worker is not configured independently to avoid having duplicate data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Predicting: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ab7958741d74366935b37e05db327cc"}},"metadata":{}},{"name":"stdout","text":"\n📊 Средние значения метрик и время вычисления:\n🧠 rankme                         = 41.2565 | ⏱ 0.0001 сек\n🧠 coherence                      = 4.0483 | ⏱ 0.0001 сек\n🧠 pseudo_condition_number        = 0.0000 | ⏱ 0.0000 сек\n🧠 alpha_req                      = 6.0476 | ⏱ 0.0002 сек\n🧠 stable_rank                    = 1.1545 | ⏱ 0.0001 сек\n🧠 ne_sum                         = 6.7743 | ⏱ 0.0016 сек\n🧠 self_clustering                = 0.7493 | ⏱ 0.0012 сек\n🧠 ripser                         = -1523.5705 | ⏱ 0.1894 сек\n----------\n0    13\nName: early_stop_epoch, dtype: int64\nProcessing checkpoint number 12\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/data.py:123: Your `IterableDataset` has `__len__` defined. In combination with multi-process data loading (when num_workers > 1), `__len__` could be inaccurate if each worker is not configured independently to avoid having duplicate data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Predicting: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3121efb2697243349af9f9908497e0d6"}},"metadata":{}},{"name":"stdout","text":"\n📊 Средние значения метрик и время вычисления:\n🧠 rankme                         = 41.5653 | ⏱ 0.0001 сек\n🧠 coherence                      = 4.1193 | ⏱ 0.0001 сек\n🧠 pseudo_condition_number        = 0.0000 | ⏱ 0.0000 сек\n🧠 alpha_req                      = 5.9646 | ⏱ 0.0002 сек\n🧠 stable_rank                    = 1.1540 | ⏱ 0.0001 сек\n🧠 ne_sum                         = 6.8588 | ⏱ 0.0017 сек\n🧠 self_clustering                = 0.7500 | ⏱ 0.0013 сек\n🧠 ripser                         = -1524.3628 | ⏱ 0.1844 сек\n----------\n0    13\nName: early_stop_epoch, dtype: int64\nProcessing checkpoint number 13\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/data.py:123: Your `IterableDataset` has `__len__` defined. In combination with multi-process data loading (when num_workers > 1), `__len__` could be inaccurate if each worker is not configured independently to avoid having duplicate data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Predicting: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1541ded2909b4dacac0219e65c906687"}},"metadata":{}},{"name":"stdout","text":"\n📊 Средние значения метрик и время вычисления:\n🧠 rankme                         = 41.3169 | ⏱ 0.0001 сек\n🧠 coherence                      = 3.9419 | ⏱ 0.0001 сек\n🧠 pseudo_condition_number        = 0.0000 | ⏱ 0.0000 сек\n🧠 alpha_req                      = 5.9508 | ⏱ 0.0002 сек\n🧠 stable_rank                    = 1.1473 | ⏱ 0.0001 сек\n🧠 ne_sum                         = 6.9654 | ⏱ 0.0017 сек\n🧠 self_clustering                = 0.7588 | ⏱ 0.0013 сек\n🧠 ripser                         = -1513.6134 | ⏱ 0.1903 сек\n----------\n0    13\nName: early_stop_epoch, dtype: int64\nProcessing checkpoint number 14\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/data.py:123: Your `IterableDataset` has `__len__` defined. In combination with multi-process data loading (when num_workers > 1), `__len__` could be inaccurate if each worker is not configured independently to avoid having duplicate data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Predicting: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18864fb0c3824390be1655a90c4afe3b"}},"metadata":{}},{"name":"stdout","text":"\n📊 Средние значения метрик и время вычисления:\n🧠 rankme                         = 41.1086 | ⏱ 0.0001 сек\n🧠 coherence                      = 4.0362 | ⏱ 0.0001 сек\n🧠 pseudo_condition_number        = 0.0000 | ⏱ 0.0000 сек\n🧠 alpha_req                      = 5.9095 | ⏱ 0.0002 сек\n🧠 stable_rank                    = 1.1501 | ⏱ 0.0001 сек\n🧠 ne_sum                         = 6.5107 | ⏱ 0.0017 сек\n🧠 self_clustering                = 0.7552 | ⏱ 0.0012 сек\n🧠 ripser                         = -1501.4334 | ⏱ 0.1852 сек\n----------\n0    13\nName: early_stop_epoch, dtype: int64\nProcessing checkpoint number 15\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/data.py:123: Your `IterableDataset` has `__len__` defined. In combination with multi-process data loading (when num_workers > 1), `__len__` could be inaccurate if each worker is not configured independently to avoid having duplicate data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Predicting: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"93dce8cb20c142ce8dafed2794a82b39"}},"metadata":{}},{"name":"stdout","text":"\n📊 Средние значения метрик и время вычисления:\n🧠 rankme                         = 41.6017 | ⏱ 0.0001 сек\n🧠 coherence                      = 3.8750 | ⏱ 0.0001 сек\n🧠 pseudo_condition_number        = 0.0000 | ⏱ 0.0000 сек\n🧠 alpha_req                      = 5.9920 | ⏱ 0.0002 сек\n🧠 stable_rank                    = 1.1486 | ⏱ 0.0001 сек\n🧠 ne_sum                         = 7.0037 | ⏱ 0.0017 сек\n🧠 self_clustering                = 0.7570 | ⏱ 0.0012 сек\n🧠 ripser                         = -1512.4178 | ⏱ 0.1873 сек\n----------\n0    13\nName: early_stop_epoch, dtype: int64\nProcessing checkpoint number 16\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/data.py:123: Your `IterableDataset` has `__len__` defined. In combination with multi-process data loading (when num_workers > 1), `__len__` could be inaccurate if each worker is not configured independently to avoid having duplicate data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Predicting: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"70a06075d5694eb0af3276dbc8259e4c"}},"metadata":{}},{"name":"stdout","text":"\n📊 Средние значения метрик и время вычисления:\n🧠 rankme                         = 40.8560 | ⏱ 0.0001 сек\n🧠 coherence                      = 4.1678 | ⏱ 0.0001 сек\n🧠 pseudo_condition_number        = 0.0000 | ⏱ 0.0000 сек\n🧠 alpha_req                      = 5.9794 | ⏱ 0.0002 сек\n🧠 stable_rank                    = 1.1457 | ⏱ 0.0001 сек\n🧠 ne_sum                         = 6.8938 | ⏱ 0.0017 сек\n🧠 self_clustering                = 0.7605 | ⏱ 0.0012 сек\n🧠 ripser                         = -1499.2965 | ⏱ 0.1913 сек\n----------\n0    13\nName: early_stop_epoch, dtype: int64\nProcessing checkpoint number 17\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/data.py:123: Your `IterableDataset` has `__len__` defined. In combination with multi-process data loading (when num_workers > 1), `__len__` could be inaccurate if each worker is not configured independently to avoid having duplicate data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Predicting: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"937509e07f5d43a7ac631d16073127a8"}},"metadata":{}},{"name":"stdout","text":"\n📊 Средние значения метрик и время вычисления:\n🧠 rankme                         = 41.4260 | ⏱ 0.0001 сек\n🧠 coherence                      = 4.0734 | ⏱ 0.0001 сек\n🧠 pseudo_condition_number        = 0.0000 | ⏱ 0.0000 сек\n🧠 alpha_req                      = 5.9455 | ⏱ 0.0002 сек\n🧠 stable_rank                    = 1.1514 | ⏱ 0.0001 сек\n🧠 ne_sum                         = 6.9511 | ⏱ 0.0017 сек\n🧠 self_clustering                = 0.7533 | ⏱ 0.0012 сек\n🧠 ripser                         = -1517.0432 | ⏱ 0.1914 сек\n----------\n0    13\nName: early_stop_epoch, dtype: int64\nRemoving checkpoints for parameters: {'batch_size': 16, 'learning_rate': 0.001, 'split_count': 3, 'cnt_min': 10, 'cnt_max': 50, 'embedding_dim': 16, 'category_embedding_dim': 8, 'hidden_size': 128}\nAll params are frozen except batch_size\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/lightning_fabric/connector.py:572: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n/usr/local/lib/python3.10/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints exists and is not empty.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Sanity Checking: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/data.py:123: Your `IterableDataset` has `__len__` defined. In combination with multi-process data loading (when num_workers > 1), `__len__` could be inaccurate if each worker is not configured independently to avoid having duplicate data.\n/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"adb22f0c60a94df892eada29464e654d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Elapsed time: 3510.14 seconds\nEarly stop is 10\nProcessing checkpoint number 0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Predicting: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b299077f8f2e4b2cbd5a6fde7c2b572e"}},"metadata":{}},{"name":"stdout","text":"\n📊 Средние значения метрик и время вычисления:\n🧠 rankme                         = 37.5522 | ⏱ 0.0001 сек\n🧠 coherence                      = 3.2292 | ⏱ 0.0001 сек\n🧠 pseudo_condition_number        = 0.0007 | ⏱ 0.0000 сек\n🧠 alpha_req                      = 4.2938 | ⏱ 0.0002 сек\n🧠 stable_rank                    = 1.1610 | ⏱ 0.0001 сек\n🧠 ne_sum                         = 6.3444 | ⏱ 0.0018 сек\n🧠 self_clustering                = 0.7421 | ⏱ 0.0012 сек\n🧠 ripser                         = -924.5758 | ⏱ 0.1962 сек\n----------\n0    10\nName: early_stop_epoch, dtype: int64\nProcessing checkpoint number 1\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/data.py:123: Your `IterableDataset` has `__len__` defined. In combination with multi-process data loading (when num_workers > 1), `__len__` could be inaccurate if each worker is not configured independently to avoid having duplicate data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Predicting: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"99928e48bb94461198dfba97862915bf"}},"metadata":{}},{"name":"stdout","text":"\n📊 Средние значения метрик и время вычисления:\n🧠 rankme                         = 40.5015 | ⏱ 0.0001 сек\n🧠 coherence                      = 2.7051 | ⏱ 0.0001 сек\n🧠 pseudo_condition_number        = 0.0002 | ⏱ 0.0000 сек\n🧠 alpha_req                      = 4.3109 | ⏱ 0.0002 сек\n🧠 stable_rank                    = 1.1429 | ⏱ 0.0001 сек\n🧠 ne_sum                         = 6.1286 | ⏱ 0.0017 сек\n🧠 self_clustering                = 0.7648 | ⏱ 0.0012 сек\n🧠 ripser                         = -1089.6054 | ⏱ 0.2033 сек\n----------\n0    10\nName: early_stop_epoch, dtype: int64\nProcessing checkpoint number 2\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/data.py:123: Your `IterableDataset` has `__len__` defined. In combination with multi-process data loading (when num_workers > 1), `__len__` could be inaccurate if each worker is not configured independently to avoid having duplicate data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Predicting: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"62b76f75ef3b45d0a89a0bca020c264f"}},"metadata":{}},{"name":"stdout","text":"\n📊 Средние значения метрик и время вычисления:\n🧠 rankme                         = 43.0277 | ⏱ 0.0001 сек\n🧠 coherence                      = 2.4057 | ⏱ 0.0001 сек\n🧠 pseudo_condition_number        = 0.0001 | ⏱ 0.0000 сек\n🧠 alpha_req                      = 4.3689 | ⏱ 0.0002 сек\n🧠 stable_rank                    = 1.1421 | ⏱ 0.0001 сек\n🧠 ne_sum                         = 6.5831 | ⏱ 0.0018 сек\n🧠 self_clustering                = 0.7658 | ⏱ 0.0013 сек\n🧠 ripser                         = -1203.9705 | ⏱ 0.1992 сек\n----------\n0    10\nName: early_stop_epoch, dtype: int64\nProcessing checkpoint number 3\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/data.py:123: Your `IterableDataset` has `__len__` defined. In combination with multi-process data loading (when num_workers > 1), `__len__` could be inaccurate if each worker is not configured independently to avoid having duplicate data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Predicting: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a385d871f684371abc80b73f8216411"}},"metadata":{}},{"name":"stdout","text":"\n📊 Средние значения метрик и время вычисления:\n🧠 rankme                         = 45.1072 | ⏱ 0.0001 сек\n🧠 coherence                      = 2.5250 | ⏱ 0.0001 сек\n🧠 pseudo_condition_number        = 0.0002 | ⏱ 0.0000 сек\n🧠 alpha_req                      = 4.2398 | ⏱ 0.0002 сек\n🧠 stable_rank                    = 1.1424 | ⏱ 0.0001 сек\n🧠 ne_sum                         = 7.5317 | ⏱ 0.0017 сек\n🧠 self_clustering                = 0.7652 | ⏱ 0.0012 сек\n🧠 ripser                         = -1290.9795 | ⏱ 0.2091 сек\n----------\n0    10\nName: early_stop_epoch, dtype: int64\nProcessing checkpoint number 4\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/data.py:123: Your `IterableDataset` has `__len__` defined. In combination with multi-process data loading (when num_workers > 1), `__len__` could be inaccurate if each worker is not configured independently to avoid having duplicate data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Predicting: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"313097ffa3174f81b1456bf7eddc6892"}},"metadata":{}},{"name":"stdout","text":"\n📊 Средние значения метрик и время вычисления:\n🧠 rankme                         = 46.5404 | ⏱ 0.0001 сек\n🧠 coherence                      = 2.6911 | ⏱ 0.0001 сек\n🧠 pseudo_condition_number        = 0.0001 | ⏱ 0.0000 сек\n🧠 alpha_req                      = 4.4234 | ⏱ 0.0002 сек\n🧠 stable_rank                    = 1.1461 | ⏱ 0.0001 сек\n🧠 ne_sum                         = 7.9824 | ⏱ 0.0017 сек\n🧠 self_clustering                = 0.7603 | ⏱ 0.0012 сек\n🧠 ripser                         = -1452.1275 | ⏱ 0.2236 сек\n----------\n0    10\nName: early_stop_epoch, dtype: int64\nProcessing checkpoint number 8\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/data.py:123: Your `IterableDataset` has `__len__` defined. In combination with multi-process data loading (when num_workers > 1), `__len__` could be inaccurate if each worker is not configured independently to avoid having duplicate data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Predicting: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f4bdc69167e448aadee50b3184f6445"}},"metadata":{}},{"name":"stdout","text":"\n📊 Средние значения метрик и время вычисления:\n🧠 rankme                         = 46.0506 | ⏱ 0.0001 сек\n🧠 coherence                      = 2.7538 | ⏱ 0.0001 сек\n🧠 pseudo_condition_number        = 0.0001 | ⏱ 0.0000 сек\n🧠 alpha_req                      = 4.6168 | ⏱ 0.0002 сек\n🧠 stable_rank                    = 1.1427 | ⏱ 0.0001 сек\n🧠 ne_sum                         = 8.3923 | ⏱ 0.0017 сек\n🧠 self_clustering                = 0.7647 | ⏱ 0.0011 сек\n🧠 ripser                         = -1457.5014 | ⏱ 0.2283 сек\n----------\n0    10\nName: early_stop_epoch, dtype: int64\nProcessing checkpoint number 9\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/data.py:123: Your `IterableDataset` has `__len__` defined. In combination with multi-process data loading (when num_workers > 1), `__len__` could be inaccurate if each worker is not configured independently to avoid having duplicate data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Predicting: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2660906b4f284260ad9762fe03d0fc78"}},"metadata":{}},{"name":"stdout","text":"\n📊 Средние значения метрик и время вычисления:\n🧠 rankme                         = 47.3355 | ⏱ 0.0001 сек\n🧠 coherence                      = 3.0700 | ⏱ 0.0001 сек\n🧠 pseudo_condition_number        = 0.0001 | ⏱ 0.0000 сек\n🧠 alpha_req                      = 4.3912 | ⏱ 0.0002 сек\n🧠 stable_rank                    = 1.1534 | ⏱ 0.0001 сек\n🧠 ne_sum                         = 8.6948 | ⏱ 0.0017 сек\n🧠 self_clustering                = 0.7506 | ⏱ 0.0012 сек\n🧠 ripser                         = -1501.3368 | ⏱ 0.2277 сек\n----------\n0    10\nName: early_stop_epoch, dtype: int64\nProcessing checkpoint number 10\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/data.py:123: Your `IterableDataset` has `__len__` defined. In combination with multi-process data loading (when num_workers > 1), `__len__` could be inaccurate if each worker is not configured independently to avoid having duplicate data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Predicting: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4587af7afc7546fc952e63ac7b8c571a"}},"metadata":{}},{"name":"stdout","text":"\n📊 Средние значения метрик и время вычисления:\n🧠 rankme                         = 46.0119 | ⏱ 0.0001 сек\n🧠 coherence                      = 2.9224 | ⏱ 0.0001 сек\n🧠 pseudo_condition_number        = 0.0001 | ⏱ 0.0000 сек\n🧠 alpha_req                      = 4.4538 | ⏱ 0.0002 сек\n🧠 stable_rank                    = 1.1406 | ⏱ 0.0001 сек\n🧠 ne_sum                         = 8.3604 | ⏱ 0.0017 сек\n🧠 self_clustering                = 0.7677 | ⏱ 0.0012 сек\n🧠 ripser                         = -1450.8107 | ⏱ 0.2260 сек\n----------\n0    10\nName: early_stop_epoch, dtype: int64\nProcessing checkpoint number 11\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/data.py:123: Your `IterableDataset` has `__len__` defined. In combination with multi-process data loading (when num_workers > 1), `__len__` could be inaccurate if each worker is not configured independently to avoid having duplicate data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Predicting: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be59f5d998a74ccea58b3e3d5aa618d6"}},"metadata":{}},{"name":"stdout","text":"\n📊 Средние значения метрик и время вычисления:\n🧠 rankme                         = 46.8065 | ⏱ 0.0001 сек\n🧠 coherence                      = 2.8744 | ⏱ 0.0001 сек\n🧠 pseudo_condition_number        = 0.0001 | ⏱ 0.0000 сек\n🧠 alpha_req                      = 4.4393 | ⏱ 0.0002 сек\n🧠 stable_rank                    = 1.1430 | ⏱ 0.0001 сек\n🧠 ne_sum                         = 7.8331 | ⏱ 0.0017 сек\n🧠 self_clustering                = 0.7644 | ⏱ 0.0011 сек\n🧠 ripser                         = -1463.7508 | ⏱ 0.2280 сек\n----------\n0    10\nName: early_stop_epoch, dtype: int64\nProcessing checkpoint number 12\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/data.py:123: Your `IterableDataset` has `__len__` defined. In combination with multi-process data loading (when num_workers > 1), `__len__` could be inaccurate if each worker is not configured independently to avoid having duplicate data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Predicting: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47aef789a3954f07aea16904dd9e6c2b"}},"metadata":{}},{"name":"stdout","text":"\n📊 Средние значения метрик и время вычисления:\n🧠 rankme                         = 47.2726 | ⏱ 0.0001 сек\n🧠 coherence                      = 2.8655 | ⏱ 0.0001 сек\n🧠 pseudo_condition_number        = 0.0001 | ⏱ 0.0000 сек\n🧠 alpha_req                      = 4.4338 | ⏱ 0.0002 сек\n🧠 stable_rank                    = 1.1528 | ⏱ 0.0001 сек\n🧠 ne_sum                         = 7.6579 | ⏱ 0.0018 сек\n🧠 self_clustering                = 0.7515 | ⏱ 0.0012 сек\n🧠 ripser                         = -1496.1508 | ⏱ 0.2159 сек\n----------\n0    10\nName: early_stop_epoch, dtype: int64\nProcessing checkpoint number 13\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/data.py:123: Your `IterableDataset` has `__len__` defined. In combination with multi-process data loading (when num_workers > 1), `__len__` could be inaccurate if each worker is not configured independently to avoid having duplicate data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Predicting: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"656c85cd3c914b5cabb2ea1045eda0ec"}},"metadata":{}},{"name":"stdout","text":"\n📊 Средние значения метрик и время вычисления:\n🧠 rankme                         = 46.4009 | ⏱ 0.0001 сек\n🧠 coherence                      = 3.1394 | ⏱ 0.0001 сек\n🧠 pseudo_condition_number        = 0.0002 | ⏱ 0.0000 сек\n🧠 alpha_req                      = 4.3636 | ⏱ 0.0002 сек\n🧠 stable_rank                    = 1.1475 | ⏱ 0.0001 сек\n🧠 ne_sum                         = 7.7645 | ⏱ 0.0018 сек\n🧠 self_clustering                = 0.7587 | ⏱ 0.0012 сек\n🧠 ripser                         = -1469.0162 | ⏱ 0.2107 сек\n----------\n0    10\nName: early_stop_epoch, dtype: int64\nProcessing checkpoint number 14\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/data.py:123: Your `IterableDataset` has `__len__` defined. In combination with multi-process data loading (when num_workers > 1), `__len__` could be inaccurate if each worker is not configured independently to avoid having duplicate data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Predicting: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"88c7b60017d14992ab89c40af7877c69"}},"metadata":{}},{"name":"stdout","text":"\n📊 Средние значения метрик и время вычисления:\n🧠 rankme                         = 46.8691 | ⏱ 0.0001 сек\n🧠 coherence                      = 2.8418 | ⏱ 0.0001 сек\n🧠 pseudo_condition_number        = 0.0001 | ⏱ 0.0000 сек\n🧠 alpha_req                      = 4.3651 | ⏱ 0.0002 сек\n🧠 stable_rank                    = 1.1486 | ⏱ 0.0001 сек\n🧠 ne_sum                         = 7.4669 | ⏱ 0.0017 сек\n🧠 self_clustering                = 0.7570 | ⏱ 0.0012 сек\n🧠 ripser                         = -1479.4593 | ⏱ 0.2159 сек\n----------\n0    10\nName: early_stop_epoch, dtype: int64\nRemoving checkpoints for parameters: {'batch_size': 32, 'learning_rate': 0.001, 'split_count': 3, 'cnt_min': 10, 'cnt_max': 50, 'embedding_dim': 16, 'category_embedding_dim': 8, 'hidden_size': 128}\nAll params are frozen except batch_size\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/lightning_fabric/connector.py:572: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n/usr/local/lib/python3.10/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints exists and is not empty.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Sanity Checking: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/data.py:123: Your `IterableDataset` has `__len__` defined. In combination with multi-process data loading (when num_workers > 1), `__len__` could be inaccurate if each worker is not configured independently to avoid having duplicate data.\n/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d39f266ba7343da901f743db190f9f3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Elapsed time: 5672.79 seconds\nEarly stop is 14\nProcessing checkpoint number 0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Predicting: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47ac98b833dd43ddb36be7de02bfa53b"}},"metadata":{}},{"name":"stdout","text":"\n📊 Средние значения метрик и время вычисления:\n🧠 rankme                         = 37.3234 | ⏱ 0.0001 сек\n🧠 coherence                      = 3.3860 | ⏱ 0.0001 сек\n🧠 pseudo_condition_number        = 0.0015 | ⏱ 0.0000 сек\n🧠 alpha_req                      = 4.2324 | ⏱ 0.0002 сек\n🧠 stable_rank                    = 1.1730 | ⏱ 0.0001 сек\n🧠 ne_sum                         = 6.9198 | ⏱ 0.0018 сек\n🧠 self_clustering                = 0.7268 | ⏱ 0.0012 сек\n🧠 ripser                         = -759.1466 | ⏱ 0.1777 сек\n----------\n0    14\nName: early_stop_epoch, dtype: int64\nProcessing checkpoint number 1\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/data.py:123: Your `IterableDataset` has `__len__` defined. In combination with multi-process data loading (when num_workers > 1), `__len__` could be inaccurate if each worker is not configured independently to avoid having duplicate data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Predicting: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e5f3837a34f74ca695b7ca38a2391dcd"}},"metadata":{}},{"name":"stdout","text":"\n📊 Средние значения метрик и время вычисления:\n🧠 rankme                         = 40.0106 | ⏱ 0.0001 сек\n🧠 coherence                      = 2.8558 | ⏱ 0.0001 сек\n🧠 pseudo_condition_number        = 0.0011 | ⏱ 0.0000 сек\n🧠 alpha_req                      = 4.0511 | ⏱ 0.0002 сек\n🧠 stable_rank                    = 1.1360 | ⏱ 0.0001 сек\n🧠 ne_sum                         = 7.5442 | ⏱ 0.0017 сек\n🧠 self_clustering                = 0.7731 | ⏱ 0.0012 сек\n🧠 ripser                         = -902.3928 | ⏱ 0.2015 сек\n----------\n0    14\nName: early_stop_epoch, dtype: int64\nProcessing checkpoint number 2\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/data.py:123: Your `IterableDataset` has `__len__` defined. In combination with multi-process data loading (when num_workers > 1), `__len__` could be inaccurate if each worker is not configured independently to avoid having duplicate data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Predicting: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"250be2a8bcb94fada3b5f29f86606c37"}},"metadata":{}},{"name":"stdout","text":"\n📊 Средние значения метрик и время вычисления:\n🧠 rankme                         = 41.2387 | ⏱ 0.0001 сек\n🧠 coherence                      = 2.5970 | ⏱ 0.0001 сек\n🧠 pseudo_condition_number        = 0.0007 | ⏱ 0.0000 сек\n🧠 alpha_req                      = 4.0286 | ⏱ 0.0002 сек\n🧠 stable_rank                    = 1.1302 | ⏱ 0.0001 сек\n🧠 ne_sum                         = 7.4430 | ⏱ 0.0017 сек\n🧠 self_clustering                = 0.7815 | ⏱ 0.0012 сек\n🧠 ripser                         = -993.8527 | ⏱ 0.2122 сек\n----------\n0    14\nName: early_stop_epoch, dtype: int64\nProcessing checkpoint number 3\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/data.py:123: Your `IterableDataset` has `__len__` defined. In combination with multi-process data loading (when num_workers > 1), `__len__` could be inaccurate if each worker is not configured independently to avoid having duplicate data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Predicting: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cab5321419ca44fd92cf5f2b45f32e40"}},"metadata":{}},{"name":"stdout","text":"\n📊 Средние значения метрик и время вычисления:\n🧠 rankme                         = 43.3379 | ⏱ 0.0001 сек\n🧠 coherence                      = 2.4141 | ⏱ 0.0001 сек\n🧠 pseudo_condition_number        = 0.0005 | ⏱ 0.0000 сек\n🧠 alpha_req                      = 3.9572 | ⏱ 0.0002 сек\n🧠 stable_rank                    = 1.1378 | ⏱ 0.0001 сек\n🧠 ne_sum                         = 7.7649 | ⏱ 0.0017 сек\n🧠 self_clustering                = 0.7712 | ⏱ 0.0012 сек\n🧠 ripser                         = -1088.5142 | ⏱ 0.2024 сек\n----------\n0    14\nName: early_stop_epoch, dtype: int64\nProcessing checkpoint number 4\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/data.py:123: Your `IterableDataset` has `__len__` defined. In combination with multi-process data loading (when num_workers > 1), `__len__` could be inaccurate if each worker is not configured independently to avoid having duplicate data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Predicting: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a7c599b744894eaf9b87ed7207b9ba23"}},"metadata":{}},{"name":"stdout","text":"\n📊 Средние значения метрик и время вычисления:\n🧠 rankme                         = 43.3290 | ⏱ 0.0001 сек\n🧠 coherence                      = 2.4586 | ⏱ 0.0001 сек\n🧠 pseudo_condition_number        = 0.0004 | ⏱ 0.0000 сек\n🧠 alpha_req                      = 3.9794 | ⏱ 0.0002 сек\n🧠 stable_rank                    = 1.1336 | ⏱ 0.0001 сек\n🧠 ne_sum                         = 7.6308 | ⏱ 0.0017 сек\n🧠 self_clustering                = 0.7767 | ⏱ 0.0012 сек\n🧠 ripser                         = -1112.3928 | ⏱ 0.1931 сек\n----------\n0    14\nName: early_stop_epoch, dtype: int64\nProcessing checkpoint number 5\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/data.py:123: Your `IterableDataset` has `__len__` defined. In combination with multi-process data loading (when num_workers > 1), `__len__` could be inaccurate if each worker is not configured independently to avoid having duplicate data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Predicting: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"644c20a7ef25453d9d3163baaea1efde"}},"metadata":{}},{"name":"stdout","text":"\n📊 Средние значения метрик и время вычисления:\n🧠 rankme                         = 44.7237 | ⏱ 0.0001 сек\n🧠 coherence                      = 2.2984 | ⏱ 0.0001 сек\n🧠 pseudo_condition_number        = 0.0005 | ⏱ 0.0000 сек\n🧠 alpha_req                      = 3.9024 | ⏱ 0.0002 сек\n🧠 stable_rank                    = 1.1327 | ⏱ 0.0001 сек\n🧠 ne_sum                         = 7.9061 | ⏱ 0.0017 сек\n🧠 self_clustering                = 0.7778 | ⏱ 0.0012 сек\n🧠 ripser                         = -1160.2242 | ⏱ 0.1993 сек\n----------\n0    14\nName: early_stop_epoch, dtype: int64\nProcessing checkpoint number 6\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/data.py:123: Your `IterableDataset` has `__len__` defined. In combination with multi-process data loading (when num_workers > 1), `__len__` could be inaccurate if each worker is not configured independently to avoid having duplicate data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Predicting: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1a194e7bd2142529c1ddc75f3075d2d"}},"metadata":{}},{"name":"stdout","text":"\n📊 Средние значения метрик и время вычисления:\n🧠 rankme                         = 46.5134 | ⏱ 0.0001 сек\n🧠 coherence                      = 2.4816 | ⏱ 0.0001 сек\n🧠 pseudo_condition_number        = 0.0005 | ⏱ 0.0000 сек\n🧠 alpha_req                      = 3.8527 | ⏱ 0.0002 сек\n🧠 stable_rank                    = 1.1458 | ⏱ 0.0001 сек\n🧠 ne_sum                         = 7.6953 | ⏱ 0.0017 сек\n🧠 self_clustering                = 0.7602 | ⏱ 0.0012 сек\n🧠 ripser                         = -1215.5551 | ⏱ 0.2043 сек\n----------\n0    14\nName: early_stop_epoch, dtype: int64\nProcessing checkpoint number 7\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/data.py:123: Your `IterableDataset` has `__len__` defined. In combination with multi-process data loading (when num_workers > 1), `__len__` could be inaccurate if each worker is not configured independently to avoid having duplicate data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Predicting: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"528ab7b757124d7aa475064bb4d05651"}},"metadata":{}},{"name":"stdout","text":"\n📊 Средние значения метрик и время вычисления:\n🧠 rankme                         = 45.3620 | ⏱ 0.0001 сек\n🧠 coherence                      = 2.2213 | ⏱ 0.0001 сек\n🧠 pseudo_condition_number        = 0.0003 | ⏱ 0.0000 сек\n🧠 alpha_req                      = 3.9544 | ⏱ 0.0002 сек\n🧠 stable_rank                    = 1.1372 | ⏱ 0.0001 сек\n🧠 ne_sum                         = 7.6484 | ⏱ 0.0018 сек\n🧠 self_clustering                = 0.7718 | ⏱ 0.0012 сек\n🧠 ripser                         = -1217.9061 | ⏱ 0.1959 сек\n----------\n0    14\nName: early_stop_epoch, dtype: int64\nProcessing checkpoint number 8\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/data.py:123: Your `IterableDataset` has `__len__` defined. In combination with multi-process data loading (when num_workers > 1), `__len__` could be inaccurate if each worker is not configured independently to avoid having duplicate data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Predicting: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bfc971a9805d41c99444c74cfa0aebf8"}},"metadata":{}},{"name":"stdout","text":"\n📊 Средние значения метрик и время вычисления:\n🧠 rankme                         = 46.5114 | ⏱ 0.0001 сек\n🧠 coherence                      = 2.2721 | ⏱ 0.0001 сек\n🧠 pseudo_condition_number        = 0.0004 | ⏱ 0.0000 сек\n🧠 alpha_req                      = 3.9005 | ⏱ 0.0002 сек\n🧠 stable_rank                    = 1.1438 | ⏱ 0.0001 сек\n🧠 ne_sum                         = 7.7009 | ⏱ 0.0017 сек\n🧠 self_clustering                = 0.7628 | ⏱ 0.0013 сек\n🧠 ripser                         = -1259.2097 | ⏱ 0.2068 сек\n----------\n0    14\nName: early_stop_epoch, dtype: int64\nProcessing checkpoint number 9\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/data.py:123: Your `IterableDataset` has `__len__` defined. In combination with multi-process data loading (when num_workers > 1), `__len__` could be inaccurate if each worker is not configured independently to avoid having duplicate data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Predicting: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"792f3cb40d7749f0bf107ef8e674c31b"}},"metadata":{}}],"execution_count":null},{"id":"b2679bf0-29dc-41d4-808a-6ec4dfcb1cb3","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}